{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samibahig/AutomaticSeedDetection/blob/main/DataScience%5BNLTK%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zgq2zlOBNyL"
      },
      "source": [
        "<center><h1> IFT-6758  Data Science  </h1></center>\n",
        "<center><h2> Fall - 2021 </h2></center>\n",
        "<center><h3> Lab - Week 12</h3></center>\n",
        "<center><h3> </h3></center>\n",
        "<center><h3>Natural Language Processing using NLTK</h3></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLgJBaNEESt4"
      },
      "source": [
        "The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing for English written in the Python programming language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cktk0XlzBeO9"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcvkYvd1v1Hb",
        "outputId": "80b04dec-8ae2-4211-9656-2245cc7f5d7b"
      },
      "source": [
        "# install nltk package\n",
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7bBEwVdxWE7",
        "outputId": "a0b22fee-3b37-4357-c8f1-bba0bbe6af6d"
      },
      "source": [
        "# it's always a good idea to check the version in your env\n",
        "import nltk\n",
        "print('Using NLTK version {}.'.format(nltk.__version__))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using NLTK version 3.8.1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw3qblzMEPeM"
      },
      "source": [
        "# NLTK Modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh--MWVMxpbS"
      },
      "source": [
        "We need a few modules for this lab; you can always download any that you need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xg1NJNBaBctU",
        "outputId": "3b02d792-ab92-4869-d0b2-68eeb815df60"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrOgPqG0EYfp"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-8E2QW-x4GW"
      },
      "source": [
        "Tokenizing a sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgRuqSQNAcxT",
        "outputId": "95036988-cd19-49a2-b93c-a750abb76ae5"
      },
      "source": [
        "sentence = \"\"\"At eight o'clock on Thursday morning... Arthur didn't feel very good.\"\"\"\n",
        "tokens = nltk.word_tokenize(sentence)\n",
        "tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['At',\n",
              " 'eight',\n",
              " \"o'clock\",\n",
              " 'on',\n",
              " 'Thursday',\n",
              " 'morning',\n",
              " '...',\n",
              " 'Arthur',\n",
              " 'did',\n",
              " \"n't\",\n",
              " 'feel',\n",
              " 'very',\n",
              " 'good',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NfnijdNEa-o"
      },
      "source": [
        "## POS Tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvxptRL7A3WY",
        "outputId": "8d7755ed-5667-4457-f8ac-ef0e67c589a4"
      },
      "source": [
        "tagged = nltk.pos_tag(tokens)\n",
        "tagged[0:6]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('At', 'IN'),\n",
              " ('eight', 'CD'),\n",
              " (\"o'clock\", 'NN'),\n",
              " ('on', 'IN'),\n",
              " ('Thursday', 'NNP'),\n",
              " ('morning', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DilHdgIAROPl",
        "outputId": "1ae5e74e-bb3d-44dc-97fa-c57bfae8f728"
      },
      "source": [
        "nltk.download('tagsets')\n",
        "nltk.help.upenn_tagset()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "$: dollar\n",
            "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
            "'': closing quotation mark\n",
            "    ' ''\n",
            "(: opening parenthesis\n",
            "    ( [ {\n",
            "): closing parenthesis\n",
            "    ) ] }\n",
            ",: comma\n",
            "    ,\n",
            "--: dash\n",
            "    --\n",
            ".: sentence terminator\n",
            "    . ! ?\n",
            ":: colon or ellipsis\n",
            "    : ; ...\n",
            "CC: conjunction, coordinating\n",
            "    & 'n and both but either et for less minus neither nor or plus so\n",
            "    therefore times v. versus vs. whether yet\n",
            "CD: numeral, cardinal\n",
            "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
            "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
            "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
            "DT: determiner\n",
            "    all an another any both del each either every half la many much nary\n",
            "    neither no some such that the them these this those\n",
            "EX: existential there\n",
            "    there\n",
            "FW: foreign word\n",
            "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
            "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
            "    terram fiche oui corporis ...\n",
            "IN: preposition or conjunction, subordinating\n",
            "    astride among uppon whether out inside pro despite on by throughout\n",
            "    below within for towards near behind atop around if like until below\n",
            "    next into if beside ...\n",
            "JJ: adjective or numeral, ordinal\n",
            "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
            "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
            "    multilingual multi-disciplinary ...\n",
            "JJR: adjective, comparative\n",
            "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
            "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
            "    cozier creamier crunchier cuter ...\n",
            "JJS: adjective, superlative\n",
            "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
            "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
            "    dearest deepest densest dinkiest ...\n",
            "LS: list item marker\n",
            "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
            "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
            "    two\n",
            "MD: modal auxiliary\n",
            "    can cannot could couldn't dare may might must need ought shall should\n",
            "    shouldn't will would\n",
            "NN: noun, common, singular or mass\n",
            "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
            "    investment slide humour falloff slick wind hyena override subhumanity\n",
            "    machinist ...\n",
            "NNP: noun, proper, singular\n",
            "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
            "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
            "    Shannon A.K.C. Meltex Liverpool ...\n",
            "NNPS: noun, proper, plural\n",
            "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
            "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
            "    Apache Apaches Apocrypha ...\n",
            "NNS: noun, common, plural\n",
            "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
            "    divestitures storehouses designs clubs fragrances averages\n",
            "    subjectivists apprehensions muses factory-jobs ...\n",
            "PDT: pre-determiner\n",
            "    all both half many quite such sure this\n",
            "POS: genitive marker\n",
            "    ' 's\n",
            "PRP: pronoun, personal\n",
            "    hers herself him himself hisself it itself me myself one oneself ours\n",
            "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
            "PRP$: pronoun, possessive\n",
            "    her his mine my our ours their thy your\n",
            "RB: adverb\n",
            "    occasionally unabatingly maddeningly adventurously professedly\n",
            "    stirringly prominently technologically magisterially predominately\n",
            "    swiftly fiscally pitilessly ...\n",
            "RBR: adverb, comparative\n",
            "    further gloomier grander graver greater grimmer harder harsher\n",
            "    healthier heavier higher however larger later leaner lengthier less-\n",
            "    perfectly lesser lonelier longer louder lower more ...\n",
            "RBS: adverb, superlative\n",
            "    best biggest bluntest earliest farthest first furthest hardest\n",
            "    heartiest highest largest least less most nearest second tightest worst\n",
            "RP: particle\n",
            "    aboard about across along apart around aside at away back before behind\n",
            "    by crop down ever fast for forth from go high i.e. in into just later\n",
            "    low more off on open out over per pie raising start teeth that through\n",
            "    under unto up up-pp upon whole with you\n",
            "SYM: symbol\n",
            "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
            "TO: \"to\" as preposition or infinitive marker\n",
            "    to\n",
            "UH: interjection\n",
            "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
            "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
            "    man baby diddle hush sonuvabitch ...\n",
            "VB: verb, base form\n",
            "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
            "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
            "    boost brace break bring broil brush build ...\n",
            "VBD: verb, past tense\n",
            "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
            "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
            "    speculated wore appreciated contemplated ...\n",
            "VBG: verb, present participle or gerund\n",
            "    telegraphing stirring focusing angering judging stalling lactating\n",
            "    hankerin' alleging veering capping approaching traveling besieging\n",
            "    encrypting interrupting erasing wincing ...\n",
            "VBN: verb, past participle\n",
            "    multihulled dilapidated aerosolized chaired languished panelized used\n",
            "    experimented flourished imitated reunifed factored condensed sheared\n",
            "    unsettled primed dubbed desired ...\n",
            "VBP: verb, present tense, not 3rd person singular\n",
            "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
            "    appear tend stray glisten obtain comprise detest tease attract\n",
            "    emphasize mold postpone sever return wag ...\n",
            "VBZ: verb, present tense, 3rd person singular\n",
            "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
            "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
            "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
            "WDT: WH-determiner\n",
            "    that what whatever which whichever\n",
            "WP: WH-pronoun\n",
            "    that what whatever whatsoever which who whom whosoever\n",
            "WP$: WH-pronoun, possessive\n",
            "    whose\n",
            "WRB: Wh-adverb\n",
            "    how however whence whenever where whereby whereever wherein whereof why\n",
            "``: opening quotation mark\n",
            "    ` ``\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYWiYP4fEiy-"
      },
      "source": [
        "## Chunking: Named entities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0hRWkZrBFMP",
        "outputId": "37c12908-af86-4216-dbec-70adaf1c03b3"
      },
      "source": [
        "import matplotlib\n",
        "\n",
        "matplotlib.use('Agg')\n",
        "entities = nltk.chunk.ne_chunk(tagged)\n",
        "print(entities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  At/IN\n",
            "  eight/CD\n",
            "  o'clock/NN\n",
            "  on/IN\n",
            "  Thursday/NNP\n",
            "  morning/NN\n",
            "  .../:\n",
            "  (PERSON Arthur/NNP)\n",
            "  did/VBD\n",
            "  n't/RB\n",
            "  feel/VB\n",
            "  very/RB\n",
            "  good/JJ\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1m86cdKHN5J"
      },
      "source": [
        "## Introducing Spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "dfamiCFxGe1X",
        "outputId": "9de556c8-e117-499b-a295-bd91c7ed32f3"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "from spacy import displacy\n",
        "\n",
        "doc = nlp(\"\"\"\n",
        "When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously. “I can tell you very senior CEOs of major American car companies would shake my hand and turn away because I wasn’t worth talking to,” said Thrun, now the co-founder and CEO of online higher education startup Udacity, in an interview with Recode earlier this week.\n",
        "A little less than a decade later, dozens of self-driving startups have cropped up while automakers around the world clamor, wallet in hand, to secure their place in the fast-moving world of fully automated transportation.\n",
        "\"\"\")\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></br>When \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Sebastian Thrun\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " started working on self-driving cars at \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Google\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2007\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", few people outside of the company took him seriously. “I can tell you very senior CEOs of major \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    American\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " car companies would shake my hand and turn away because I wasn’t worth talking to,” said \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Thrun\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", now the co-founder and CEO of online higher education startup Udacity, in an interview with \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Recode\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    earlier this week\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ".</br>A little \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    less than a decade later\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    dozens\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " of self-driving startups have cropped up while automakers around the world clamor, wallet in hand, to secure their place in the fast-moving world of fully automated transportation.</br></div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dpw9eNYvFyCH"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn26kEst8jox"
      },
      "source": [
        "# IMDB Dataset for Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcSrnK6CIazL",
        "outputId": "7b7bbd6c-ea80-46a1-ec8c-350e3254cec7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget -O \"imdb_train.txt\" \"https://raw.githubusercontent.com/Jhelum-Ch/DataScience_IFT6758/gh-pages/media/train.txt\"\n",
        "!wget -O \"imdb_test.txt\" \"https://raw.githubusercontent.com/Jhelum-Ch/DataScience_IFT6758/gh-pages/media/test.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-19 20:55:26--  https://raw.githubusercontent.com/Jhelum-Ch/DataScience_IFT6758/gh-pages/media/train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 172996 (169K) [text/plain]\n",
            "Saving to: ‘imdb_train.txt’\n",
            "\n",
            "\rimdb_train.txt        0%[                    ]       0  --.-KB/s               \rimdb_train.txt      100%[===================>] 168.94K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2023-07-19 20:55:26 (41.4 MB/s) - ‘imdb_train.txt’ saved [172996/172996]\n",
            "\n",
            "--2023-07-19 20:55:26--  https://raw.githubusercontent.com/Jhelum-Ch/DataScience_IFT6758/gh-pages/media/test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31822 (31K) [text/plain]\n",
            "Saving to: ‘imdb_test.txt’\n",
            "\n",
            "imdb_test.txt       100%[===================>]  31.08K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-07-19 20:55:26 (154 MB/s) - ‘imdb_test.txt’ saved [31822/31822]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmGan5KTI6pv"
      },
      "source": [
        "You can create a list\n",
        "of tuples where the first item is the review and the second item is the sentiment, i.e., ‘0’ or\n",
        "‘1’."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emj_ASEkygXM"
      },
      "source": [
        "def dataset_generator(f):\n",
        "    file = open(f)\n",
        "    contents = file.read().splitlines()\n",
        "    data = [tuple(x.split(\"\\t\")) for x in contents]\n",
        "    file.close()\n",
        "    return data\n",
        "\n",
        "train_data = dataset_generator(\"imdb_train.txt\")\n",
        "test_data = dataset_generator(\"imdb_test.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdq9gTC1-MW2",
        "outputId": "1e231f2c-864f-44c2-b27f-09bb51748667"
      },
      "source": [
        "print(train_data[0])\n",
        "print(train_data[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('So there is no way for me to plug it in here in the US unless I go by a converter.', '0')\n",
            "('Good case, Excellent value.', '1')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeZbFnXoJEj8"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1GkWgoyJHvu"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y79gzm9LJJKR",
        "outputId": "8e603fbe-b154-4469-d77b-e5e04c0baedb"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def generate_tokens(data):\n",
        "    X = []\n",
        "    for x in data:\n",
        "        try:\n",
        "            # lowercase -> tokenize -> append to list\n",
        "            X.append((word_tokenize(x[0].lower()), x[1]))\n",
        "        except:\n",
        "            pass\n",
        "    return X\n",
        "\n",
        "X_train_tokens = generate_tokens(train_data)\n",
        "X_test_tokens = generate_tokens(test_data)\n",
        "\n",
        "print(X_train_tokens[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['and', 'the', 'sound', 'quality', 'is', 'great', '.'], '1')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEF0eQVyKECv"
      },
      "source": [
        "## Frequency Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8boQWW2cKG7p",
        "outputId": "b03b7823-e131-4fb8-a278-423c3985fd6e"
      },
      "source": [
        "from nltk.probability import FreqDist\n",
        "\n",
        "all_word_list = []\n",
        "for sentences in X_train_tokens:\n",
        "    for token in sentences[0]:\n",
        "        all_word_list.append(token)\n",
        "\n",
        "fdist = FreqDist(all_word_list)\n",
        "fdist.most_common(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('.', 2188),\n",
              " ('the', 1602),\n",
              " (',', 1115),\n",
              " ('and', 961),\n",
              " ('i', 875),\n",
              " ('a', 751),\n",
              " ('it', 663),\n",
              " ('is', 636),\n",
              " ('to', 568),\n",
              " ('this', 546)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNwDPjT5KRPG"
      },
      "source": [
        "## Stopword Removal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sShofPCn6Mt2"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNvQJmakKTQd",
        "outputId": "58f004c4-2f0d-49d4-b280-1d36413ba7cc"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "stopwords_english = stopwords.words('english')\n",
        "\n",
        "# Removing both stopwords and punctuations\n",
        "filtered_word_list = [word for word in all_word_list if word not in stopwords_english and word not in string.punctuation]\n",
        "\n",
        "fdist = FreqDist(filtered_word_list)\n",
        "fdist.most_common(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"n't\", 233),\n",
              " (\"'s\", 216),\n",
              " ('good', 187),\n",
              " ('great', 169),\n",
              " ('movie', 153),\n",
              " ('phone', 141),\n",
              " ('film', 139),\n",
              " ('one', 121),\n",
              " ('food', 98),\n",
              " ('like', 93)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsDFM0AiKSwV"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5NqAJsoKwlT"
      },
      "source": [
        "## Stemming VS Lematization\n",
        "\n",
        "\n",
        "1.   If you lemmatize the word 'Caring', it would return 'Care'. If you stem, it would return 'Car' and this is erroneous.\n",
        "2.   If you lemmatize the word 'Stripes' in verb context, it would return 'Strip'. If you lemmatize it in noun context, it would return 'Stripe'. If you just stem it, it would just return 'Strip'.\n",
        "3. You would get same results whether you lemmatize or stem words such as walking, running, swimming... to walk, run, swim etc.  \n",
        "4. Lemmatization is computationally expensive since it involves look-up tables and what not. If you have large dataset and performance is an issue, go with Stemming. Remember you can also add your own rules to Stemming. If accuracy is paramount and dataset isn't humongous, go with Lemmatization.  \n",
        "\n",
        "Source: https://stackoverflow.com/a/59752867  \n",
        "Reference: https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNAyOljxEIdP"
      },
      "source": [
        "**Stemming**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvqcJ8_AEzm7",
        "outputId": "4035098e-61ad-439f-aa78-8eaefe7589d4"
      },
      "source": [
        "# import these modules\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "ps = SnowballStemmer('english')\n",
        "\n",
        "# choose some words to be stemmed\n",
        "words = [\"program\", \"programs\", \"programer\", \"programing\", \"programers\"]\n",
        "for w in words:\n",
        "    print(w, \" : \", ps.stem(w))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "program  :  program\n",
            "programs  :  program\n",
            "programer  :  program\n",
            "programing  :  program\n",
            "programers  :  program\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0z_O7_XClgr"
      },
      "source": [
        "**Lemmatization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg8m2cLjCkie",
        "outputId": "70cb57da-2dcc-4055-fa2c-5e870e6e8d53"
      },
      "source": [
        "# import these modules\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
        "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
        "# a denotes adjective in \"pos\"\n",
        "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rocks : rock\n",
            "corpora : corpus\n",
            "better : good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhlTvYUdLEpc"
      },
      "source": [
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "def preprocess(data):\n",
        "    '''\n",
        "    Running Stopwords, Stemming on X_train\n",
        "    '''\n",
        "    X = []\n",
        "    for token_list, label in data:\n",
        "        new_word_list = [stemmer.stem(word) for word in token_list if word not in stopwords_english and word not in string.punctuation]\n",
        "        X.append((new_word_list, label))\n",
        "\n",
        "    return X\n",
        "\n",
        "X_train_tokens_processed = preprocess(X_train_tokens)\n",
        "X_test_tokens_processed = preprocess(X_test_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdGzbbQmK-xA"
      },
      "source": [
        "## Vocabulary Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eenky_CgLBW9"
      },
      "source": [
        "def generate_vectors(data, vocab):\n",
        "    '''\n",
        "    Build vocabulary and generate vectors\n",
        "    '''\n",
        "    X_vectors = []\n",
        "    for sentence, label in data:\n",
        "        vec = {}\n",
        "        for token in vocab:\n",
        "            if token in sentence:\n",
        "                vec[token] = 1\n",
        "            else:\n",
        "                vec[token]= 0\n",
        "        X_vectors.append((vec, label))\n",
        "    return X_vectors\n",
        "\n",
        "from nltk.stem import SnowballStemmer\n",
        "stemmer = SnowballStemmer('english')\n",
        "stemmed_filtered_word_list = [stemmer.stem(word) for word in filtered_word_list]\n",
        "\n",
        "train_set = generate_vectors(X_train_tokens_processed, stemmed_filtered_word_list)\n",
        "test_set = generate_vectors(X_test_tokens_processed, stemmed_filtered_word_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG2IMGAKJZ1F",
        "outputId": "616a8b60-713d-42aa-bfe6-c86aa9f174e1"
      },
      "source": [
        "vocab_length = len(train_set[0][0].items())\n",
        "vocab_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3747"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHPONBVGL9Oi"
      },
      "source": [
        "train_set is a list of tuple of feature_dictionary and label.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqXU-XdRL6zb",
        "outputId": "bcc1942e-5055-4586-91ef-9be242934936"
      },
      "source": [
        "len(train_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2500"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4pVHeGWME0U",
        "outputId": "37c30605-347b-405b-bfc7-8a28fdc190ea"
      },
      "source": [
        "train_set[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'way': 1,\n",
              "  'plug': 1,\n",
              "  'us': 1,\n",
              "  'unless': 1,\n",
              "  'go': 1,\n",
              "  'convert': 1,\n",
              "  'good': 0,\n",
              "  'case': 0,\n",
              "  'excel': 0,\n",
              "  'valu': 0,\n",
              "  'great': 0,\n",
              "  'jawbon': 0,\n",
              "  'tie': 0,\n",
              "  'charger': 0,\n",
              "  'convers': 0,\n",
              "  'last': 0,\n",
              "  '45': 0,\n",
              "  'minutes.major': 0,\n",
              "  'problem': 0,\n",
              "  'mic': 0,\n",
              "  'jiggl': 0,\n",
              "  'get': 0,\n",
              "  'line': 0,\n",
              "  'right': 0,\n",
              "  'decent': 0,\n",
              "  'volum': 0,\n",
              "  'sever': 0,\n",
              "  'dozen': 0,\n",
              "  'hundr': 0,\n",
              "  'contact': 0,\n",
              "  'imagin': 0,\n",
              "  'fun': 0,\n",
              "  'send': 0,\n",
              "  'one': 0,\n",
              "  'razr': 0,\n",
              "  'owner': 0,\n",
              "  '...': 0,\n",
              "  'must': 0,\n",
              "  'needless': 0,\n",
              "  'say': 0,\n",
              "  'wast': 0,\n",
              "  'money': 0,\n",
              "  'time': 0,\n",
              "  'sound': 0,\n",
              "  'qualiti': 0,\n",
              "  'impress': 0,\n",
              "  'origin': 0,\n",
              "  'batteri': 0,\n",
              "  'extend': 0,\n",
              "  'two': 0,\n",
              "  'seper': 0,\n",
              "  'mere': 0,\n",
              "  '5+': 0,\n",
              "  'ft': 0,\n",
              "  'start': 0,\n",
              "  'notic': 0,\n",
              "  'excess': 0,\n",
              "  'static': 0,\n",
              "  'garbl': 0,\n",
              "  'headset': 0,\n",
              "  'though': 0,\n",
              "  'design': 0,\n",
              "  'odd': 0,\n",
              "  'ear': 0,\n",
              "  '``': 0,\n",
              "  'clip': 0,\n",
              "  \"''\": 0,\n",
              "  'comfort': 0,\n",
              "  'high': 0,\n",
              "  'recommend': 0,\n",
              "  'blue': 0,\n",
              "  'tooth': 0,\n",
              "  'phone': 0,\n",
              "  'advis': 0,\n",
              "  'everyon': 0,\n",
              "  'fool': 0,\n",
              "  'far': 0,\n",
              "  'work': 0,\n",
              "  'click': 0,\n",
              "  'place': 0,\n",
              "  'make': 0,\n",
              "  'wonder': 0,\n",
              "  'long': 0,\n",
              "  'mechan': 0,\n",
              "  'would': 0,\n",
              "  'went': 0,\n",
              "  'motorola': 0,\n",
              "  \"'s\": 0,\n",
              "  'websit': 0,\n",
              "  'follow': 0,\n",
              "  'direct': 0,\n",
              "  'could': 0,\n",
              "  'pair': 0,\n",
              "  'bought': 0,\n",
              "  'use': 0,\n",
              "  'kindl': 0,\n",
              "  'fire': 0,\n",
              "  'absolut': 0,\n",
              "  'love': 0,\n",
              "  'commerci': 0,\n",
              "  'mislead': 0,\n",
              "  'yet': 0,\n",
              "  'run': 0,\n",
              "  'new': 0,\n",
              "  'bar': 0,\n",
              "  'three': 0,\n",
              "  'day': 0,\n",
              "  'without': 0,\n",
              "  'charg': 0,\n",
              "  'mother': 0,\n",
              "  'pocket': 0,\n",
              "  'pc': 0,\n",
              "  'combin': 0,\n",
              "  've': 0,\n",
              "  'own': 0,\n",
              "  '7': 0,\n",
              "  'month': 0,\n",
              "  'best': 0,\n",
              "  'mobil': 0,\n",
              "  \"n't\": 0,\n",
              "  'think': 0,\n",
              "  'instruct': 0,\n",
              "  'provid': 0,\n",
              "  'help': 0,\n",
              "  'peopl': 0,\n",
              "  'couldnt': 0,\n",
              "  'hear': 0,\n",
              "  'talk': 0,\n",
              "  'pull': 0,\n",
              "  'earphon': 0,\n",
              "  'hold': 0,\n",
              "  'simpl': 0,\n",
              "  'littl': 0,\n",
              "  'breakag': 0,\n",
              "  'unaccept': 0,\n",
              "  'product': 0,\n",
              "  'ideal': 0,\n",
              "  'like': 0,\n",
              "  'whose': 0,\n",
              "  'sensit': 0,\n",
              "  'unus': 0,\n",
              "  'move': 0,\n",
              "  'car': 0,\n",
              "  'freeway': 0,\n",
              "  'speed': 0,\n",
              "  'year': 0,\n",
              "  'left': 0,\n",
              "  'contract': 0,\n",
              "  'hate': 0,\n",
              "  'well': 0,\n",
              "  'ac': 0,\n",
              "  'includ': 0,\n",
              "  'sure': 0,\n",
              "  'never': 0,\n",
              "  'juice.highi': 0,\n",
              "  'need': 0,\n",
              "  'least': 0,\n",
              "  '3': 0,\n",
              "  'min': 0,\n",
              "  'book': 0,\n",
              "  'first': 0,\n",
              "  'turn': 0,\n",
              "  'phone.batteri': 0,\n",
              "  'life': 0,\n",
              "  'short': 0,\n",
              "  'kept': 0,\n",
              "  'poor': 0,\n",
              "  'perform': 0,\n",
              "  'def': 0,\n",
              "  'come': 0,\n",
              "  'back': 0,\n",
              "  'bowl': 0,\n",
              "  'next': 0,\n",
              "  'want': 0,\n",
              "  'healthi': 0,\n",
              "  'authent': 0,\n",
              "  'ethic': 0,\n",
              "  'food': 0,\n",
              "  'tri': 0,\n",
              "  'continu': 0,\n",
              "  'ladi': 0,\n",
              "  'night': 0,\n",
              "  'andddd': 0,\n",
              "  'date': 0,\n",
              "  'anyon': 0,\n",
              "  'area': 0,\n",
              "  'past': 0,\n",
              "  'experi': 0,\n",
              "  'alway': 0,\n",
              "  'walk': 0,\n",
              "  'away': 0,\n",
              "  'stuf': 0,\n",
              "  'happi': 0,\n",
              "  'vega': 0,\n",
              "  'buffet': 0,\n",
              "  'servic': 0,\n",
              "  'price': 0,\n",
              "  'pretti': 0,\n",
              "  'reason': 0,\n",
              "  'consid': 0,\n",
              "  'locat': 0,\n",
              "  'insid': 0,\n",
              "  'crystal': 0,\n",
              "  'shop': 0,\n",
              "  'mall': 0,\n",
              "  'aria': 0,\n",
              "  'summar': 0,\n",
              "  'incred': 0,\n",
              "  'nay': 0,\n",
              "  'transcend': 0,\n",
              "  'noth': 0,\n",
              "  'bring': 0,\n",
              "  'joy': 0,\n",
              "  'quit': 0,\n",
              "  'memori': 0,\n",
              "  'pneumat': 0,\n",
              "  'condiment': 0,\n",
              "  'dispens': 0,\n",
              "  \"'m\": 0,\n",
              "  'probabl': 0,\n",
              "  'ever': 0,\n",
              "  'ian': 0,\n",
              "  'kid': 0,\n",
              "  'pizza': 0,\n",
              "  'hit': 0,\n",
              "  'lot': 0,\n",
              "  'side': 0,\n",
              "  'dish': 0,\n",
              "  'option': 0,\n",
              "  'kiddo': 0,\n",
              "  'perfect': 0,\n",
              "  'famili': 0,\n",
              "  'atmospher': 0,\n",
              "  'nice': 0,\n",
              "  'see': 0,\n",
              "  'cook': 0,\n",
              "  'impecc': 0,\n",
              "  'simpli': 0,\n",
              "  'disappoint': 0,\n",
              "  'overal': 0,\n",
              "  'bouchon': 0,\n",
              "  'account': 0,\n",
              "  'know': 0,\n",
              "  'screw': 0,\n",
              "  'eat': 0,\n",
              "  'remind': 0,\n",
              "  'mom': 0,\n",
              "  'pop': 0,\n",
              "  'san': 0,\n",
              "  'francisco': 0,\n",
              "  'bay': 0,\n",
              "  'today': 0,\n",
              "  'tast': 0,\n",
              "  'buldogi': 0,\n",
              "  'gourmet': 0,\n",
              "  'hot': 0,\n",
              "  'dog': 0,\n",
              "  'tell': 0,\n",
              "  'thought': 0,\n",
              "  'possibl': 0,\n",
              "  'frustrat': 0,\n",
              "  'll': 0,\n",
              "  'definit': 0,\n",
              "  'soon': 0,\n",
              "  'realli': 0,\n",
              "  'got': 0,\n",
              "  'full': 0,\n",
              "  'petti': 0,\n",
              "  'fast': 0,\n",
              "  'fantast': 0,\n",
              "  'total': 0,\n",
              "  'kind': 0,\n",
              "  'ice': 0,\n",
              "  'tea': 0,\n",
              "  'hungri': 0,\n",
              "  'leav': 0,\n",
              "  'give': 0,\n",
              "  'star': 0,\n",
              "  'assur': 0,\n",
              "  'wo': 0,\n",
              "  'take': 0,\n",
              "  'bad': 0,\n",
              "  'suck': 0,\n",
              "  'gave': 0,\n",
              "  'crust': 0,\n",
              "  'teeth': 0,\n",
              "  'still': 0,\n",
              "  'sore': 0,\n",
              "  'complet': 0,\n",
              "  'gross': 0,\n",
              "  'enjoy': 0,\n",
              "  'quick': 0,\n",
              "  'becom': 0,\n",
              "  'regular': 0,\n",
              "  'server': 0,\n",
              "  'even': 0,\n",
              "  'look': 0,\n",
              "  'overwhelm': 0,\n",
              "  'stay': 0,\n",
              "  'profession': 0,\n",
              "  'friend': 0,\n",
              "  'end': 0,\n",
              "  'dinner': 0,\n",
              "  'companion': 0,\n",
              "  'told': 0,\n",
              "  'everyth': 0,\n",
              "  'fresh': 0,\n",
              "  'textur': 0,\n",
              "  'ground': 0,\n",
              "  'tabl': 0,\n",
              "  'larg': 0,\n",
              "  'smear': 0,\n",
              "  'been-stepped-in-and-tracked-everywher': 0,\n",
              "  'pile': 0,\n",
              "  'green': 0,\n",
              "  'bird': 0,\n",
              "  'poop': 0,\n",
              "  'furthermor': 0,\n",
              "  'ca': 0,\n",
              "  'find': 0,\n",
              "  'hour': 0,\n",
              "  'oper': 0,\n",
              "  '10+': 0,\n",
              "  're': 0,\n",
              "  'done': 0,\n",
              "  'mistak': 0,\n",
              "  'complaint': 0,\n",
              "  'serious': 0,\n",
              "  'expert/connisseur': 0,\n",
              "  'topic': 0,\n",
              "  'waiter': 0,\n",
              "  'jerk': 0,\n",
              "  'strike': 0,\n",
              "  '2': 0,\n",
              "  'rush': 0,\n",
              "  'nicest': 0,\n",
              "  'restaur': 0,\n",
              "  'across': 0,\n",
              "  'biscuit': 0,\n",
              "  'order': 0,\n",
              "  'appet': 0,\n",
              "  'took': 0,\n",
              "  '40': 0,\n",
              "  'minut': 0,\n",
              "  'anoth': 0,\n",
              "  '10': 0,\n",
              "  'absolutley': 0,\n",
              "  'huge': 0,\n",
              "  'awkward': 0,\n",
              "  '1.5lb': 0,\n",
              "  'piec': 0,\n",
              "  'cow': 0,\n",
              "  '3/4ths': 0,\n",
              "  'gristl': 0,\n",
              "  'fat': 0,\n",
              "  'steiner': 0,\n",
              "  'dark': 0,\n",
              "  'feel': 0,\n",
              "  'wow': 0,\n",
              "  'spici': 0,\n",
              "  'delici': 0,\n",
              "  'familiar': 0,\n",
              "  'check': 0,\n",
              "  'busi': 0,\n",
              "  'dollar': 0,\n",
              "  'elsewher': 0,\n",
              "  \"'d\": 0,\n",
              "  'anyway': 0,\n",
              "  'fs': 0,\n",
              "  'breakfast/lunch': 0,\n",
              "  'special': 0,\n",
              "  'week': 0,\n",
              "  'differ': 0,\n",
              "  'deal': 0,\n",
              "  'mention': 0,\n",
              "  'pear': 0,\n",
              "  'almond': 0,\n",
              "  'bacon': 0,\n",
              "  'big': 0,\n",
              "  'winner': 0,\n",
              "  'sauc': 0,\n",
              "  'tasteless': 0,\n",
              "  'enough': 0,\n",
              "  'ask': 0,\n",
              "  'spicier': 0,\n",
              "  'prefer': 0,\n",
              "  'ribey': 0,\n",
              "  'steak': 0,\n",
              "  'mesquit': 0,\n",
              "  'flavor': 0,\n",
              "  'anytim': 0,\n",
              "  'gooodd': 0,\n",
              "  'sushi': 0,\n",
              "  'connoisseur': 0,\n",
              "  'certain': 0,\n",
              "  'insult': 0,\n",
              "  'lunch': 0,\n",
              "  'chicken': 0,\n",
              "  'wing': 0,\n",
              "  'contain': 0,\n",
              "  'driest': 0,\n",
              "  'meat': 0,\n",
              "  'eaten': 0,\n",
              "  'everi': 0,\n",
              "  'mouth': 0,\n",
              "  'relax': 0,\n",
              "  'venu': 0,\n",
              "  'coupl': 0,\n",
              "  'small': 0,\n",
              "  'group': 0,\n",
              "  'etc': 0,\n",
              "  'nargil': 0,\n",
              "  'tater': 0,\n",
              "  'tot': 0,\n",
              "  'southwest': 0,\n",
              "  'worth': 0,\n",
              "  'paid': 0,\n",
              "  'vanilla': 0,\n",
              "  'cream': 0,\n",
              "  'creami': 0,\n",
              "  'smooth': 0,\n",
              "  'profiterol': 0,\n",
              "  'choux': 0,\n",
              "  'pastri': 0,\n",
              "  'im': 0,\n",
              "  'az': 0,\n",
              "  'spot': 0,\n",
              "  'manag': 0,\n",
              "  'worst': 0,\n",
              "  'clean': 0,\n",
              "  'outstand': 0,\n",
              "  'due': 0,\n",
              "  'fact': 0,\n",
              "  '20': 0,\n",
              "  'acknowledg': 0,\n",
              "  '35': 0,\n",
              "  'forget': 0,\n",
              "  'thing': 0,\n",
              "  'margarita': 0,\n",
              "  'note': 0,\n",
              "  'ventil': 0,\n",
              "  'upgrad': 0,\n",
              "  'pork': 0,\n",
              "  'sandwich': 0,\n",
              "  'letdown': 0,\n",
              "  'much': 0,\n",
              "  'rather': 0,\n",
              "  'camelback': 0,\n",
              "  'flower': 0,\n",
              "  'cartel': 0,\n",
              "  'coffe': 0,\n",
              "  'third': 0,\n",
              "  'chees': 0,\n",
              "  'burger': 0,\n",
              "  'cold': 0,\n",
              "  'brunch': 0,\n",
              "  'trim': 0,\n",
              "  'also': 0,\n",
              "  '70+': 0,\n",
              "  'claim': 0,\n",
              "  'handl': 0,\n",
              "  'beauti': 0,\n",
              "  'bill': 0,\n",
              "  'either': 0,\n",
              "  'jewel': 0,\n",
              "  'las': 0,\n",
              "  'exact': 0,\n",
              "  'hope': 0,\n",
              "  'near': 0,\n",
              "  'ten': 0,\n",
              "  'live': 0,\n",
              "  'seafood': 0,\n",
              "  'limit': 0,\n",
              "  'boil': 0,\n",
              "  'shrimp': 0,\n",
              "  'crab': 0,\n",
              "  'leg': 0,\n",
              "  'select': 0,\n",
              "  'fine': 0,\n",
              "  'dine': 0,\n",
              "  'establish': 0,\n",
              "  'toro': 0,\n",
              "  'tartar': 0,\n",
              "  'cavier': 0,\n",
              "  'extraordinari': 0,\n",
              "  'thin': 0,\n",
              "  'slice': 0,\n",
              "  'wagyu': 0,\n",
              "  'white': 0,\n",
              "  'truffl': 0,\n",
              "  'dont': 0,\n",
              "  'attach': 0,\n",
              "  'gas': 0,\n",
              "  'station': 0,\n",
              "  'rare': 0,\n",
              "  'sign': 0,\n",
              "  'awesom': 0,\n",
              "  'mani': 0,\n",
              "  'menu': 0,\n",
              "  'stuff': 0,\n",
              "  'decid': 0,\n",
              "  'wors': 0,\n",
              "  'humili': 0,\n",
              "  'worker': 0,\n",
              "  'front': 0,\n",
              "  '..': 0,\n",
              "  'bunch': 0,\n",
              "  'horribl': 0,\n",
              "  'name': 0,\n",
              "  'call': 0,\n",
              "  'conclus': 0,\n",
              "  'fill': 0,\n",
              "  'meal': 0,\n",
              "  'daili': 0,\n",
              "  'tragedi': 0,\n",
              "  'struck': 0,\n",
              "  'pancak': 0,\n",
              "  'crawfish': 0,\n",
              "  'monster': 0,\n",
              "  'fri': 0,\n",
              "  'egg': 0,\n",
              "  'favorit': 0,\n",
              "  'waitress': 0,\n",
              "  'sweet': 0,\n",
              "  'funni': 0,\n",
              "  'multi-grain': 0,\n",
              "  'pumpkin': 0,\n",
              "  'pecan': 0,\n",
              "  'butter': 0,\n",
              "  'amaz': 0,\n",
              "  'fluffi': 0,\n",
              "  'airlin': 0,\n",
              "  'cant': 0,\n",
              "  'ambianc': 0,\n",
              "  'noca': 0,\n",
              "  'gyro': 0,\n",
              "  'basic': 0,\n",
              "  'lettuc': 0,\n",
              "  'terribl': 0,\n",
              "  'thorough': 0,\n",
              "  'pasta': 0,\n",
              "  'homemad': 0,\n",
              "  '/hand': 0,\n",
              "  'made': 0,\n",
              "  'serv': 0,\n",
              "  'blandest': 0,\n",
              "  'prepar': 0,\n",
              "  'indian': 0,\n",
              "  'cuisin': 0,\n",
              "  'boot': 0,\n",
              "  'worri': 0,\n",
              "  'guy': 0,\n",
              "  'son': 0,\n",
              "  'said': 0,\n",
              "  'ventur': 0,\n",
              "  'host': 0,\n",
              "  'staff': 0,\n",
              "  'lack': 0,\n",
              "  'better': 0,\n",
              "  'word': 0,\n",
              "  'bitch': 0,\n",
              "  'bland': 0,\n",
              "  'number': 0,\n",
              "  'review': 0,\n",
              "  'phenomen': 0,\n",
              "  'return': 0,\n",
              "  'strip': 0,\n",
              "  'belli': 0,\n",
              "  'overpr': 0,\n",
              "  'mediocr': 0,\n",
              "  'penn': 0,\n",
              "  'vodka': 0,\n",
              "  'massiv': 0,\n",
              "  'meatloaf': 0,\n",
              "  'crispi': 0,\n",
              "  'wrap': 0,\n",
              "  'delish': 0,\n",
              "  'tuna': 0,\n",
              "  'melt': 0,\n",
              "  'tasti': 0,\n",
              "  'rude': 0,\n",
              "  'nyc': 0,\n",
              "  'bagel': 0,\n",
              "  'real': 0,\n",
              "  'lox': 0,\n",
              "  'caper': 0,\n",
              "  'subway': 0,\n",
              "  'meet': 0,\n",
              "  'expect': 0,\n",
              "  'solid': 0,\n",
              "  'breakfast': 0,\n",
              "  'extrem': 0,\n",
              "  'weekend': 0,\n",
              "  'cheesecurd': 0,\n",
              "  'typic': 0,\n",
              "  'drive': 0,\n",
              "  'glanc': 0,\n",
              "  'bakeri': 0,\n",
              "  'cafe': 0,\n",
              "  'point': 0,\n",
              "  'finger': 0,\n",
              "  'item': 0,\n",
              "  'oh': 0,\n",
              "  'gone': 0,\n",
              "  'greasi': 0,\n",
              "  'unhealthi': 0,\n",
              "  'might': 0,\n",
              "  'similar': 0,\n",
              "  'deliveri': 0,\n",
              "  'man': 0,\n",
              "  'apolog': 0,\n",
              "  'late': 0,\n",
              "  'expens': 0,\n",
              "  'dessert': 0,\n",
              "  'pack': 0,\n",
              "  'to-go': 0,\n",
              "  'tiramisu': 0,\n",
              "  'cannoli': 0,\n",
              "  'die': 0,\n",
              "  'wait': 0,\n",
              "  'bartend': 0,\n",
              "  'thumb': 0,\n",
              "  '....': 0,\n",
              "  'sat': 0,\n",
              "  'sun': 0,\n",
              "  'mexican': 0,\n",
              "  'whole': 0,\n",
              "  'interest': 0,\n",
              "  'choos': 0,\n",
              "  'experienc': 0,\n",
              "  'frenchman': 0,\n",
              "  'zero': 0,\n",
              "  'wine': 0,\n",
              "  'martini': 0,\n",
              "  'opinion': 0,\n",
              "  'entre': 0,\n",
              "  'gc': 0,\n",
              "  'opportun': 0,\n",
              "  'sampl': 0,\n",
              "  'thirti': 0,\n",
              "  'seat': 0,\n",
              "  'although': 0,\n",
              "  '8': 0,\n",
              "  'vacant': 0,\n",
              "  'folk': 0,\n",
              "  'yellowtail': 0,\n",
              "  'carpaccio': 0,\n",
              "  'empti': 0,\n",
              "  'potato': 0,\n",
              "  'found': 0,\n",
              "  'stranger': 0,\n",
              "  'hair': 0,\n",
              "  'actual': 0,\n",
              "  'second': 0,\n",
              "  'hello': 0,\n",
              "  'bit': 0,\n",
              "  'strang': 0,\n",
              "  'boyfriend': 0,\n",
              "  'came': 0,\n",
              "  'recent': 0,\n",
              "  'trip': 0,\n",
              "  'pleas': 0,\n",
              "  'wrong': 0,\n",
              "  'donut': 0,\n",
              "  'save': 0,\n",
              "  'room': 0,\n",
              "  'guess': 0,\n",
              "  'mayb': 0,\n",
              "  'disgrac': 0,\n",
              "  'howev': 0,\n",
              "  'particular': 0,\n",
              "  'someth': 0,\n",
              "  'avoid': 0,\n",
              "  'suffer': 0,\n",
              "  'hard': 0,\n",
              "  'tapa': 0,\n",
              "  'heart': 0,\n",
              "  'salad': 0,\n",
              "  'vinegrett': 0,\n",
              "  'babi': 0,\n",
              "  'palm': 0,\n",
              "  'felt': 0,\n",
              "  'disgust': 0,\n",
              "  'believ': 0,\n",
              "  'stop': 0,\n",
              "  'hanker': 0,\n",
              "  'generous': 0,\n",
              "  'portion': 0,\n",
              "  'forth': 0,\n",
              "  'theft': 0,\n",
              "  'eew': 0,\n",
              "  'overhaul': 0,\n",
              "  'wit': 0,\n",
              "  'toward': 0,\n",
              "  'guest': 0,\n",
              "  'super': 0,\n",
              "  'old': 0,\n",
              "  'chewi': 0,\n",
              "  'swung': 0,\n",
              "  'deepli': 0,\n",
              "  'compani': 0,\n",
              "  'effici': 0,\n",
              "  'fan': 0,\n",
              "  'boy': 0,\n",
              "  'sucker': 0,\n",
              "  'dri': 0,\n",
              "  'rate': 0,\n",
              "  'thai': 0,\n",
              "  'els': 0,\n",
              "  '100': 0,\n",
              "  '15': 0,\n",
              "  'set': 0,\n",
              "  'cheap': 0,\n",
              "  'black': 0,\n",
              "  'oliv': 0,\n",
              "  'perpar': 0,\n",
              "  'present': 0,\n",
              "  'giant': 0,\n",
              "  'toast': 0,\n",
              "  'light': 0,\n",
              "  'dust': 0,\n",
              "  'powder': 0,\n",
              "  'sugar': 0,\n",
              "  'play': 0,\n",
              "  'nasti': 0,\n",
              "  'fo': 0,\n",
              "  'accomod': 0,\n",
              "  'vegan/veggi': 0,\n",
              "  'omg': 0,\n",
              "  'crumbi': 0,\n",
              "  'pale': 0,\n",
              "  'color': 0,\n",
              "  'instead': 0,\n",
              "  'char': 0,\n",
              "  'crouton': 0,\n",
              "  'extra': 0,\n",
              "  'plus': 0,\n",
              "  'home': 0,\n",
              "  'damn': 0,\n",
              "  'phoenix': 0,\n",
              "  'crema': 0,\n",
              "  'café': 0,\n",
              "  'expand': 0,\n",
              "  'miss': 0,\n",
              "  'wish': 0,\n",
              "  'philadelphia': 0,\n",
              "  'sit': 0,\n",
              "  'fair': 0,\n",
              "  '30': 0,\n",
              "  'arriv': 0,\n",
              "  'crisp': 0,\n",
              "  'town': 0,\n",
              "  'satisfi': 0,\n",
              "  'north': 0,\n",
              "  'scottsdal': 0,\n",
              "  'soooooo': 0,\n",
              "  'let': 0,\n",
              "  'freak': 0,\n",
              "  'paper': 0,\n",
              "  'ago': 0,\n",
              "  'reheat': 0,\n",
              "  'ok': 0,\n",
              "  'wedg': 0,\n",
              "  'soggi': 0,\n",
              "  'sorri': 0,\n",
              "  'visit': 0,\n",
              "  'tongu': 0,\n",
              "  'cheek': 0,\n",
              "  'taco': 0,\n",
              "  'bloodi': 0,\n",
              "  'mari': 0,\n",
              "  'despit': 0,\n",
              "  '1': 0,\n",
              "  'pho': 0,\n",
              "  'grill': 0,\n",
              "  'tender': 0,\n",
              "  'yellow': 0,\n",
              "  'saffron': 0,\n",
              "  'season': 0,\n",
              "  'thru': 0,\n",
              "  'mean': 0,\n",
              "  'around': 0,\n",
              "  'half': 0,\n",
              "  'somehow': 0,\n",
              "  'ambienc': 0,\n",
              "  'luck': 0,\n",
              "  'non-custom': 0,\n",
              "  'focus': 0,\n",
              "  'grandmoth': 0,\n",
              "  'roast': 0,\n",
              "  'multipl': 0,\n",
              "  'list': 0,\n",
              "  'ignor': 0,\n",
              "  'hostess': 0,\n",
              "  'especi': 0,\n",
              "  'cool': 0,\n",
              "  'four': 0,\n",
              "  'shirt': 0,\n",
              "  'vibe': 0,\n",
              "  'beef': 0,\n",
              "  'drastic': 0,\n",
              "  'sick': 0,\n",
              "  'high-qual': 0,\n",
              "  'caesar': 0,\n",
              "  'prompt': 0,\n",
              "  'greet': 0,\n",
              "  'madhous': 0,\n",
              "  'proven': 0,\n",
              "  'dead': 0,\n",
              "  'greatest': 0,\n",
              "  'mood': 0,\n",
              "  'joint': 0,\n",
              "  'macaron': 0,\n",
              "  'insan': 0,\n",
              "  'attent': 0,\n",
              "  'inform': 0,\n",
              "  'somewhat': 0,\n",
              "  'edibl': 0,\n",
              "  'promis': 0,\n",
              "  'fail': 0,\n",
              "  'deliv': 0,\n",
              "  'averag': 0,\n",
              "  'plater': 0,\n",
              "  'beer': 0,\n",
              "  'sit-down': 0,\n",
              "  'togeth': 0,\n",
              "  'construct': 0,\n",
              "  'patio': 0,\n",
              "  'rice': 0,\n",
              "  'hand': 0,\n",
              "  'italian': 0,\n",
              "  'scream': 0,\n",
              "  'legit': 0,\n",
              "  'somethat': 0,\n",
              "  'duo': 0,\n",
              "  'violinist': 0,\n",
              "  'song': 0,\n",
              "  'request': 0,\n",
              "  'person': 0,\n",
              "  'hummus': 0,\n",
              "  'pita': 0,\n",
              "  'baklava': 0,\n",
              "  'falafel': 0,\n",
              "  'baba': 0,\n",
              "  'ganoush': 0,\n",
              "  'eggplant': 0,\n",
              "  'conveni': 0,\n",
              "  'sinc': 0,\n",
              "  'mgm': 0,\n",
              "  'courteous': 0,\n",
              "  'eclect': 0,\n",
              "  'onion': 0,\n",
              "  'ring': 0,\n",
              "  'close': 0,\n",
              "  'chef': 0,\n",
              "  'twice': 0,\n",
              "  'pictur': 0,\n",
              "  'nobu': 0,\n",
              "  'googl': 0,\n",
              "  'smashburg': 0,\n",
              "  'lover': 0,\n",
              "  'doubl': 0,\n",
              "  'cheeseburg': 0,\n",
              "  'neighborhood': 0,\n",
              "  'gem': 0,\n",
              "  'plantain': 0,\n",
              "  'slow': 0,\n",
              "  '5': 0,\n",
              "  'spend': 0,\n",
              "  'panna': 0,\n",
              "  'cotta': 0,\n",
              "  'atmosphere.1': 0,\n",
              "  'slaw': 0,\n",
              "  'drench': 0,\n",
              "  'mayo': 0,\n",
              "  'decor': 0,\n",
              "  'piano': 0,\n",
              "  'music': 0,\n",
              "  'soundtrack': 0,\n",
              "  'pleasant': 0,\n",
              "  'rge': 0,\n",
              "  'fillet': 0,\n",
              "  'relleno': 0,\n",
              "  'plate': 0,\n",
              "  'honest': 0,\n",
              "  'sergeant': 0,\n",
              "  'pepper': 0,\n",
              "  'auju': 0,\n",
              "  'hawaiian': 0,\n",
              "  'breez': 0,\n",
              "  'mango': 0,\n",
              "  'magic': 0,\n",
              "  'pineappl': 0,\n",
              "  'delight': 0,\n",
              "  'smoothi': 0,\n",
              "  'mortifi': 0,\n",
              "  'pay': 0,\n",
              "  'chip': 0,\n",
              "  'drip': 0,\n",
              "  'greas': 0,\n",
              "  'most': 0,\n",
              "  '2007': 0,\n",
              "  'cashier': 0,\n",
              "  'brought': 0,\n",
              "  'hospit': 0,\n",
              "  'industri': 0,\n",
              "  'paradis': 0,\n",
              "  'valley': 0,\n",
              "  'refrain': 0,\n",
              "  'cibo': 0,\n",
              "  'longer': 0,\n",
              "  'other': 0,\n",
              "  'famous': 0,\n",
              "  'fish': 0,\n",
              "  'read': 0,\n",
              "  'pros': 0,\n",
              "  'area/': 0,\n",
              "  'drink': 0,\n",
              "  'menu/': 0,\n",
              "  'brick': 0,\n",
              "  'oven': 0,\n",
              "  'dough': 0,\n",
              "  'tonight': 0,\n",
              "  'elk': 0,\n",
              "  'filet': 0,\n",
              "  'bite': 0,\n",
              "  'hook': 0,\n",
              "  'classic': 0,\n",
              "  'cute': 0,\n",
              "  'quaint': 0,\n",
              "  'outsid': 0,\n",
              "  'moist': 0,\n",
              "  'compliment': 0,\n",
              "  'thank': 0,\n",
              "  'dylan': 0,\n",
              "  't.': 0,\n",
              "  'yummi': 0,\n",
              "  'tummi': 0,\n",
              "  'ad': 0,\n",
              "  'gratuiti': 0,\n",
              "  'parti': 0,\n",
              "  'larger': 0,\n",
              "  '6': 0,\n",
              "  'tip': 0,\n",
              "  'fli': 0,\n",
              "  'appl': 0,\n",
              "  'juic': 0,\n",
              "  'han': 0,\n",
              "  'nan': 0,\n",
              "  'bare': 0,\n",
              "  'lukewarm': 0,\n",
              "  'ryan': 0,\n",
              "  'edinburgh': 0,\n",
              "  'revisit': 0,\n",
              "  'chines': 0,\n",
              "  'naan': 0,\n",
              "  'bread': 0,\n",
              "  'pine': 0,\n",
              "  'nut': 0,\n",
              "  'world': 0,\n",
              "  '--': 0,\n",
              "  'touch': 0,\n",
              "  'airport': 0,\n",
              "  'speedi': 0,\n",
              "  'calligraphi': 0,\n",
              "  'wall': 0,\n",
              "  'anyth': 0,\n",
              "  'complain': 0,\n",
              "  'stood': 0,\n",
              "  'begin': 0,\n",
              "  'open': 0,\n",
              "  'warm': 0,\n",
              "  'treat': 0,\n",
              "  'extens': 0,\n",
              "  'vegetarian': 0,\n",
              "  'wide': 0,\n",
              "  'array': 0,\n",
              "  'watch': 0,\n",
              "  'inflat': 0,\n",
              "  'smaller': 0,\n",
              "  'attitud': 0,\n",
              "  'grow': 0,\n",
              "  'rapid': 0,\n",
              "  'lil': 0,\n",
              "  'fuzzi': 0,\n",
              "  'fabul': 0,\n",
              "  'wonton': 0,\n",
              "  'thick': 0,\n",
              "  'almost': 0,\n",
              "  'level': 0,\n",
              "  'spice': 0,\n",
              "  'over-whelm': 0,\n",
              "  'soup': 0,\n",
              "  'main': 0,\n",
              "  'crowd': 0,\n",
              "  'older': 0,\n",
              "  'mid': 0,\n",
              "  '30s': 0,\n",
              "  'arepa': 0,\n",
              "  'jalapeno': 0,\n",
              "  ...},\n",
              " '0')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OgwREcaHMXNn",
        "outputId": "77a9c441-3748-491e-833a-155aefea6163"
      },
      "source": [
        "# Label for each sentence\n",
        "train_set[0][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc_xmypFLjNO",
        "outputId": "2630ff46-d5a6-409c-aff8-59dd3387ef70"
      },
      "source": [
        "# Features for each sentence\n",
        "len(train_set[0][0].keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3747"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jtW_IdlMlU4"
      },
      "source": [
        "# Naive Bayes CLassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChQU38fP_7sB"
      },
      "source": [
        "train_set[i] == ({tokens:exisits?..}, 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrN39aKRMgSH",
        "outputId": "f5ac3db9-d17d-4b15-a8b6-ec8fec11332c"
      },
      "source": [
        "from nltk import NaiveBayesClassifier\n",
        "from nltk import classify\n",
        "\n",
        "classifier = NaiveBayesClassifier.train(train_set)\n",
        "accuracy = classify.accuracy(classifier, test_set)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X61Qx6SlNLR0"
      },
      "source": [
        "# Feature Engineering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwHT0CuDQwRY"
      },
      "source": [
        "## N-gram\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdbbqQ5VNRRy",
        "outputId": "23722f10-0ec6-4b3b-9e90-967bd82bded8"
      },
      "source": [
        "from nltk import ngrams\n",
        "\n",
        "def get_bigrams(word_tokens, n=2):\n",
        "  n_grams = ngrams(word_tokens, n)\n",
        "  return [ ' '.join(grams) for grams in n_grams]\n",
        "\n",
        "vocab_bigram = get_bigrams(stemmed_filtered_word_list)\n",
        "X_train_bigram = [(get_bigrams(x[0]),x[1]) for x in X_train_tokens_processed]\n",
        "X_test_bigram = [(get_bigrams(x[0]),x[1]) for x in X_test_tokens_processed]\n",
        "\n",
        "train_set = generate_vectors(X_train_bigram, vocab = vocab_bigram)\n",
        "test_set = generate_vectors(X_test_bigram, vocab = vocab_bigram)\n",
        "\n",
        "vocab_length = len(train_set[0][0].items())\n",
        "vocab_length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14613"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEkStQ2lRSdb",
        "outputId": "45d09561-2e9c-4d77-96d6-1a1c22faf897",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_set[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'way plug': 1,\n",
              "  'plug us': 1,\n",
              "  'us unless': 1,\n",
              "  'unless go': 1,\n",
              "  'go convert': 1,\n",
              "  'convert good': 0,\n",
              "  'good case': 0,\n",
              "  'case excel': 0,\n",
              "  'excel valu': 0,\n",
              "  'valu great': 0,\n",
              "  'great jawbon': 0,\n",
              "  'jawbon tie': 0,\n",
              "  'tie charger': 0,\n",
              "  'charger convers': 0,\n",
              "  'convers last': 0,\n",
              "  'last 45': 0,\n",
              "  '45 minutes.major': 0,\n",
              "  'minutes.major problem': 0,\n",
              "  'problem mic': 0,\n",
              "  'mic great': 0,\n",
              "  'great jiggl': 0,\n",
              "  'jiggl plug': 0,\n",
              "  'plug get': 0,\n",
              "  'get line': 0,\n",
              "  'line right': 0,\n",
              "  'right get': 0,\n",
              "  'get decent': 0,\n",
              "  'decent volum': 0,\n",
              "  'volum sever': 0,\n",
              "  'sever dozen': 0,\n",
              "  'dozen sever': 0,\n",
              "  'sever hundr': 0,\n",
              "  'hundr contact': 0,\n",
              "  'contact imagin': 0,\n",
              "  'imagin fun': 0,\n",
              "  'fun send': 0,\n",
              "  'send one': 0,\n",
              "  'one one': 0,\n",
              "  'one razr': 0,\n",
              "  'razr owner': 0,\n",
              "  'owner ...': 0,\n",
              "  '... must': 0,\n",
              "  'must needless': 0,\n",
              "  'needless say': 0,\n",
              "  'say wast': 0,\n",
              "  'wast money': 0,\n",
              "  'money wast': 0,\n",
              "  'money time': 0,\n",
              "  'time sound': 0,\n",
              "  'sound qualiti': 0,\n",
              "  'qualiti great': 0,\n",
              "  'great impress': 0,\n",
              "  'impress go': 0,\n",
              "  'go origin': 0,\n",
              "  'origin batteri': 0,\n",
              "  'batteri extend': 0,\n",
              "  'extend batteri': 0,\n",
              "  'batteri two': 0,\n",
              "  'two seper': 0,\n",
              "  'seper mere': 0,\n",
              "  'mere 5+': 0,\n",
              "  '5+ ft': 0,\n",
              "  'ft start': 0,\n",
              "  'start notic': 0,\n",
              "  'notic excess': 0,\n",
              "  'excess static': 0,\n",
              "  'static garbl': 0,\n",
              "  'garbl sound': 0,\n",
              "  'sound headset': 0,\n",
              "  'headset good': 0,\n",
              "  'good qualiti': 0,\n",
              "  'qualiti though': 0,\n",
              "  'though design': 0,\n",
              "  'design odd': 0,\n",
              "  'odd ear': 0,\n",
              "  'ear ``': 0,\n",
              "  '`` clip': 0,\n",
              "  \"clip ''\": 0,\n",
              "  \"'' comfort\": 0,\n",
              "  'comfort high': 0,\n",
              "  'high recommend': 0,\n",
              "  'recommend one': 0,\n",
              "  'one blue': 0,\n",
              "  'blue tooth': 0,\n",
              "  'tooth phone': 0,\n",
              "  'phone advis': 0,\n",
              "  'advis everyon': 0,\n",
              "  'everyon fool': 0,\n",
              "  'fool far': 0,\n",
              "  'far good': 0,\n",
              "  'good work': 0,\n",
              "  'work great': 0,\n",
              "  'great click': 0,\n",
              "  'click place': 0,\n",
              "  'place way': 0,\n",
              "  'way make': 0,\n",
              "  'make wonder': 0,\n",
              "  'wonder long': 0,\n",
              "  'long mechan': 0,\n",
              "  'mechan would': 0,\n",
              "  'would last': 0,\n",
              "  'last went': 0,\n",
              "  'went motorola': 0,\n",
              "  \"motorola 's\": 0,\n",
              "  \"'s websit\": 0,\n",
              "  'websit follow': 0,\n",
              "  'follow direct': 0,\n",
              "  'direct could': 0,\n",
              "  'could get': 0,\n",
              "  'get pair': 0,\n",
              "  'pair bought': 0,\n",
              "  'bought use': 0,\n",
              "  'use kindl': 0,\n",
              "  'kindl fire': 0,\n",
              "  'fire absolut': 0,\n",
              "  'absolut love': 0,\n",
              "  'love commerci': 0,\n",
              "  'commerci mislead': 0,\n",
              "  'mislead yet': 0,\n",
              "  'yet run': 0,\n",
              "  'run new': 0,\n",
              "  'new batteri': 0,\n",
              "  'two bar': 0,\n",
              "  \"bar 's\": 0,\n",
              "  \"'s three\": 0,\n",
              "  'three day': 0,\n",
              "  'day without': 0,\n",
              "  'without charg': 0,\n",
              "  'charg bought': 0,\n",
              "  'bought mother': 0,\n",
              "  'mother problem': 0,\n",
              "  'problem batteri': 0,\n",
              "  'batteri great': 0,\n",
              "  'great pocket': 0,\n",
              "  'pocket pc': 0,\n",
              "  'pc phone': 0,\n",
              "  'phone combin': 0,\n",
              "  'combin ve': 0,\n",
              "  've own': 0,\n",
              "  'own phone': 0,\n",
              "  'phone 7': 0,\n",
              "  '7 month': 0,\n",
              "  'month say': 0,\n",
              "  \"say 's\": 0,\n",
              "  \"'s best\": 0,\n",
              "  'best mobil': 0,\n",
              "  'mobil phone': 0,\n",
              "  'phone ve': 0,\n",
              "  \"ve n't\": 0,\n",
              "  \"n't think\": 0,\n",
              "  'think instruct': 0,\n",
              "  'instruct provid': 0,\n",
              "  'provid help': 0,\n",
              "  'help peopl': 0,\n",
              "  'peopl couldnt': 0,\n",
              "  'couldnt hear': 0,\n",
              "  'hear talk': 0,\n",
              "  'talk pull': 0,\n",
              "  'pull earphon': 0,\n",
              "  'earphon talk': 0,\n",
              "  'talk phone': 0,\n",
              "  \"phone n't\": 0,\n",
              "  \"n't hold\": 0,\n",
              "  'hold charg': 0,\n",
              "  'charg simpl': 0,\n",
              "  'simpl littl': 0,\n",
              "  'littl phone': 0,\n",
              "  'phone use': 0,\n",
              "  'use breakag': 0,\n",
              "  'breakag unaccept': 0,\n",
              "  'unaccept product': 0,\n",
              "  'product ideal': 0,\n",
              "  'ideal peopl': 0,\n",
              "  'peopl like': 0,\n",
              "  'like whose': 0,\n",
              "  'whose ear': 0,\n",
              "  'ear sensit': 0,\n",
              "  'sensit unus': 0,\n",
              "  'unus move': 0,\n",
              "  'move car': 0,\n",
              "  'car freeway': 0,\n",
              "  'freeway speed': 0,\n",
              "  'speed two': 0,\n",
              "  'two year': 0,\n",
              "  'year left': 0,\n",
              "  'left contract': 0,\n",
              "  'contract hate': 0,\n",
              "  'hate phone': 0,\n",
              "  'phone car': 0,\n",
              "  'car charger': 0,\n",
              "  'charger well': 0,\n",
              "  'well ac': 0,\n",
              "  'ac charger': 0,\n",
              "  'charger includ': 0,\n",
              "  'includ make': 0,\n",
              "  'make sure': 0,\n",
              "  'sure never': 0,\n",
              "  'never run': 0,\n",
              "  'run juice.highi': 0,\n",
              "  'juice.highi recommend': 0,\n",
              "  'recommend need': 0,\n",
              "  'need least': 0,\n",
              "  'least 3': 0,\n",
              "  '3 min': 0,\n",
              "  'min get': 0,\n",
              "  'get phone': 0,\n",
              "  'phone book': 0,\n",
              "  'book time': 0,\n",
              "  'time first': 0,\n",
              "  'first turn': 0,\n",
              "  'turn phone.batteri': 0,\n",
              "  'phone.batteri life': 0,\n",
              "  'life short': 0,\n",
              "  'short kept': 0,\n",
              "  'kept well': 0,\n",
              "  'well poor': 0,\n",
              "  'poor talk': 0,\n",
              "  'talk time': 0,\n",
              "  'time perform': 0,\n",
              "  'perform def': 0,\n",
              "  'def come': 0,\n",
              "  'come back': 0,\n",
              "  'back bowl': 0,\n",
              "  'bowl next': 0,\n",
              "  'next time': 0,\n",
              "  'time want': 0,\n",
              "  'want healthi': 0,\n",
              "  'healthi authent': 0,\n",
              "  'authent ethic': 0,\n",
              "  'ethic food': 0,\n",
              "  'food tri': 0,\n",
              "  'tri place': 0,\n",
              "  'place continu': 0,\n",
              "  'continu come': 0,\n",
              "  'come ladi': 0,\n",
              "  'ladi night': 0,\n",
              "  'night andddd': 0,\n",
              "  'andddd date': 0,\n",
              "  'date night': 0,\n",
              "  'night ...': 0,\n",
              "  '... high': 0,\n",
              "  'recommend place': 0,\n",
              "  'place anyon': 0,\n",
              "  'anyon area': 0,\n",
              "  'area sever': 0,\n",
              "  'sever time': 0,\n",
              "  'time past': 0,\n",
              "  'past experi': 0,\n",
              "  'experi alway': 0,\n",
              "  'alway great': 0,\n",
              "  'great walk': 0,\n",
              "  'walk away': 0,\n",
              "  'away stuf': 0,\n",
              "  'stuf happi': 0,\n",
              "  'happi first': 0,\n",
              "  'first vega': 0,\n",
              "  'vega buffet': 0,\n",
              "  'buffet experi': 0,\n",
              "  'experi servic': 0,\n",
              "  'servic excel': 0,\n",
              "  'excel price': 0,\n",
              "  'price pretti': 0,\n",
              "  'pretti reason': 0,\n",
              "  'reason consid': 0,\n",
              "  'consid vega': 0,\n",
              "  'vega locat': 0,\n",
              "  'locat insid': 0,\n",
              "  'insid crystal': 0,\n",
              "  'crystal shop': 0,\n",
              "  'shop mall': 0,\n",
              "  'mall aria': 0,\n",
              "  'aria summar': 0,\n",
              "  'summar ...': 0,\n",
              "  '... food': 0,\n",
              "  'food incred': 0,\n",
              "  'incred nay': 0,\n",
              "  'nay transcend': 0,\n",
              "  'transcend ...': 0,\n",
              "  '... noth': 0,\n",
              "  'noth bring': 0,\n",
              "  'bring joy': 0,\n",
              "  'joy quit': 0,\n",
              "  'quit like': 0,\n",
              "  'like memori': 0,\n",
              "  'memori pneumat': 0,\n",
              "  'pneumat condiment': 0,\n",
              "  'condiment dispens': 0,\n",
              "  \"dispens 'm\": 0,\n",
              "  \"'m probabl\": 0,\n",
              "  'probabl one': 0,\n",
              "  'one peopl': 0,\n",
              "  'peopl ever': 0,\n",
              "  'ever go': 0,\n",
              "  'go ian': 0,\n",
              "  'ian like': 0,\n",
              "  'like kid': 0,\n",
              "  'kid pizza': 0,\n",
              "  'pizza alway': 0,\n",
              "  'alway hit': 0,\n",
              "  'hit lot': 0,\n",
              "  'lot great': 0,\n",
              "  'great side': 0,\n",
              "  'side dish': 0,\n",
              "  'dish option': 0,\n",
              "  'option kiddo': 0,\n",
              "  'kiddo servic': 0,\n",
              "  'servic perfect': 0,\n",
              "  'perfect famili': 0,\n",
              "  'famili atmospher': 0,\n",
              "  'atmospher nice': 0,\n",
              "  'nice see': 0,\n",
              "  'see cook': 0,\n",
              "  'cook perfect': 0,\n",
              "  'perfect servic': 0,\n",
              "  'servic impecc': 0,\n",
              "  'impecc one': 0,\n",
              "  'one simpli': 0,\n",
              "  'simpli disappoint': 0,\n",
              "  'disappoint overal': 0,\n",
              "  'overal disappoint': 0,\n",
              "  'disappoint qualiti': 0,\n",
              "  'qualiti food': 0,\n",
              "  'food bouchon': 0,\n",
              "  \"bouchon n't\": 0,\n",
              "  \"n't account\": 0,\n",
              "  'account know': 0,\n",
              "  \"know 'm\": 0,\n",
              "  \"'m get\": 0,\n",
              "  'get screw': 0,\n",
              "  'screw great': 0,\n",
              "  'great place': 0,\n",
              "  'place eat': 0,\n",
              "  'eat remind': 0,\n",
              "  'remind littl': 0,\n",
              "  'littl mom': 0,\n",
              "  'mom pop': 0,\n",
              "  'pop shop': 0,\n",
              "  'shop san': 0,\n",
              "  'san francisco': 0,\n",
              "  'francisco bay': 0,\n",
              "  'bay area': 0,\n",
              "  'area today': 0,\n",
              "  'today first': 0,\n",
              "  'first tast': 0,\n",
              "  'tast buldogi': 0,\n",
              "  'buldogi gourmet': 0,\n",
              "  'gourmet hot': 0,\n",
              "  'hot dog': 0,\n",
              "  'dog tell': 0,\n",
              "  'tell ever': 0,\n",
              "  'ever thought': 0,\n",
              "  'thought possibl': 0,\n",
              "  'possibl left': 0,\n",
              "  'left frustrat': 0,\n",
              "  'frustrat ll': 0,\n",
              "  'll definit': 0,\n",
              "  'definit soon': 0,\n",
              "  'soon food': 0,\n",
              "  'food realli': 0,\n",
              "  'realli good': 0,\n",
              "  'good got': 0,\n",
              "  'got full': 0,\n",
              "  'full petti': 0,\n",
              "  'petti fast': 0,\n",
              "  'fast servic': 0,\n",
              "  'servic fantast': 0,\n",
              "  'fantast total': 0,\n",
              "  'total wast': 0,\n",
              "  'wast time': 0,\n",
              "  \"time n't\": 0,\n",
              "  \"n't know\": 0,\n",
              "  'know kind': 0,\n",
              "  'kind best': 0,\n",
              "  'best ice': 0,\n",
              "  'ice tea': 0,\n",
              "  'tea come': 0,\n",
              "  'come hungri': 0,\n",
              "  'hungri leav': 0,\n",
              "  'leav happi': 0,\n",
              "  'happi stuf': 0,\n",
              "  'stuf servic': 0,\n",
              "  'servic give': 0,\n",
              "  'give star': 0,\n",
              "  'star assur': 0,\n",
              "  'assur wo': 0,\n",
              "  \"wo n't\": 0,\n",
              "  \"n't disappoint\": 0,\n",
              "  'disappoint take': 0,\n",
              "  'take littl': 0,\n",
              "  'littl bad': 0,\n",
              "  'bad servic': 0,\n",
              "  'servic food': 0,\n",
              "  'food suck': 0,\n",
              "  'suck gave': 0,\n",
              "  'gave tri': 0,\n",
              "  'tri eat': 0,\n",
              "  'eat crust': 0,\n",
              "  'crust teeth': 0,\n",
              "  'teeth still': 0,\n",
              "  'still sore': 0,\n",
              "  'sore complet': 0,\n",
              "  'complet gross': 0,\n",
              "  'gross realli': 0,\n",
              "  'realli enjoy': 0,\n",
              "  'enjoy eat': 0,\n",
              "  'eat first': 0,\n",
              "  'first time': 0,\n",
              "  'time go': 0,\n",
              "  'go think': 0,\n",
              "  'think quick': 0,\n",
              "  'quick becom': 0,\n",
              "  'becom regular': 0,\n",
              "  'regular server': 0,\n",
              "  'server nice': 0,\n",
              "  'nice even': 0,\n",
              "  'even though': 0,\n",
              "  'though look': 0,\n",
              "  'look littl': 0,\n",
              "  'littl overwhelm': 0,\n",
              "  'overwhelm need': 0,\n",
              "  'need stay': 0,\n",
              "  'stay profession': 0,\n",
              "  'profession friend': 0,\n",
              "  'friend end': 0,\n",
              "  'end dinner': 0,\n",
              "  'dinner companion': 0,\n",
              "  'companion told': 0,\n",
              "  'told ...': 0,\n",
              "  '... everyth': 0,\n",
              "  'everyth fresh': 0,\n",
              "  'fresh nice': 0,\n",
              "  'nice textur': 0,\n",
              "  'textur tast': 0,\n",
              "  'tast ground': 0,\n",
              "  'ground right': 0,\n",
              "  'right next': 0,\n",
              "  'next tabl': 0,\n",
              "  'tabl larg': 0,\n",
              "  'larg smear': 0,\n",
              "  'smear been-stepped-in-and-tracked-everywher': 0,\n",
              "  'been-stepped-in-and-tracked-everywher pile': 0,\n",
              "  'pile green': 0,\n",
              "  'green bird': 0,\n",
              "  'bird poop': 0,\n",
              "  'poop furthermor': 0,\n",
              "  'furthermor ca': 0,\n",
              "  \"ca n't\": 0,\n",
              "  \"n't even\": 0,\n",
              "  'even find': 0,\n",
              "  'find hour': 0,\n",
              "  'hour oper': 0,\n",
              "  'oper websit': 0,\n",
              "  'websit ve': 0,\n",
              "  've tri': 0,\n",
              "  'tri like': 0,\n",
              "  'like place': 0,\n",
              "  'place 10+': 0,\n",
              "  '10+ time': 0,\n",
              "  'time think': 0,\n",
              "  'think re': 0,\n",
              "  're done': 0,\n",
              "  'done mistak': 0,\n",
              "  'mistak complaint': 0,\n",
              "  'complaint serious': 0,\n",
              "  'serious good': 0,\n",
              "  'good pizza': 0,\n",
              "  \"pizza 'm\": 0,\n",
              "  \"'m expert/connisseur\": 0,\n",
              "  'expert/connisseur topic': 0,\n",
              "  'topic waiter': 0,\n",
              "  'waiter jerk': 0,\n",
              "  'jerk strike': 0,\n",
              "  'strike 2': 0,\n",
              "  '2 want': 0,\n",
              "  'want rush': 0,\n",
              "  'rush nicest': 0,\n",
              "  'nicest restaur': 0,\n",
              "  'restaur owner': 0,\n",
              "  'owner ve': 0,\n",
              "  've ever': 0,\n",
              "  'ever come': 0,\n",
              "  'come across': 0,\n",
              "  'across never': 0,\n",
              "  'never come': 0,\n",
              "  'come love': 0,\n",
              "  'love biscuit': 0,\n",
              "  'biscuit servic': 0,\n",
              "  'servic quick': 0,\n",
              "  'quick friend': 0,\n",
              "  'friend order': 0,\n",
              "  'order appet': 0,\n",
              "  'appet took': 0,\n",
              "  'took 40': 0,\n",
              "  '40 minut': 0,\n",
              "  'minut pizza': 0,\n",
              "  'pizza anoth': 0,\n",
              "  'anoth 10': 0,\n",
              "  '10 minut': 0,\n",
              "  'minut absolutley': 0,\n",
              "  'absolutley fantast': 0,\n",
              "  'fantast huge': 0,\n",
              "  'huge awkward': 0,\n",
              "  'awkward 1.5lb': 0,\n",
              "  '1.5lb piec': 0,\n",
              "  'piec cow': 0,\n",
              "  'cow 3/4ths': 0,\n",
              "  '3/4ths gristl': 0,\n",
              "  'gristl fat': 0,\n",
              "  'fat definit': 0,\n",
              "  'definit come': 0,\n",
              "  'back like': 0,\n",
              "  'like steiner': 0,\n",
              "  \"steiner 's\": 0,\n",
              "  \"'s dark\": 0,\n",
              "  'dark feel': 0,\n",
              "  'feel like': 0,\n",
              "  'like bar': 0,\n",
              "  'bar wow': 0,\n",
              "  'wow spici': 0,\n",
              "  'spici delici': 0,\n",
              "  'delici re': 0,\n",
              "  're familiar': 0,\n",
              "  'familiar check': 0,\n",
              "  'check ll': 0,\n",
              "  'll take': 0,\n",
              "  'take busi': 0,\n",
              "  'busi dinner': 0,\n",
              "  'dinner dollar': 0,\n",
              "  'dollar elsewher': 0,\n",
              "  \"elsewher 'd\": 0,\n",
              "  \"'d love\": 0,\n",
              "  'love go': 0,\n",
              "  'go back': 0,\n",
              "  'back anyway': 0,\n",
              "  'anyway fs': 0,\n",
              "  'fs restaur': 0,\n",
              "  'restaur wonder': 0,\n",
              "  'wonder breakfast/lunch': 0,\n",
              "  'breakfast/lunch noth': 0,\n",
              "  'noth special': 0,\n",
              "  'special day': 0,\n",
              "  'day week': 0,\n",
              "  'week differ': 0,\n",
              "  'differ deal': 0,\n",
              "  \"deal 's\": 0,\n",
              "  \"'s delici\": 0,\n",
              "  'delici mention': 0,\n",
              "  'mention combin': 0,\n",
              "  'combin pear': 0,\n",
              "  'pear almond': 0,\n",
              "  'almond bacon': 0,\n",
              "  'bacon big': 0,\n",
              "  'big winner': 0,\n",
              "  'winner back': 0,\n",
              "  'back sauc': 0,\n",
              "  'sauc tasteless': 0,\n",
              "  'tasteless food': 0,\n",
              "  'food delici': 0,\n",
              "  'delici spici': 0,\n",
              "  'spici enough': 0,\n",
              "  'enough sure': 0,\n",
              "  'sure ask': 0,\n",
              "  'ask spicier': 0,\n",
              "  'spicier prefer': 0,\n",
              "  'prefer way': 0,\n",
              "  'way ribey': 0,\n",
              "  'ribey steak': 0,\n",
              "  'steak cook': 0,\n",
              "  'perfect great': 0,\n",
              "  'great mesquit': 0,\n",
              "  'mesquit flavor': 0,\n",
              "  \"flavor n't\": 0,\n",
              "  'think ll': 0,\n",
              "  'll go': 0,\n",
              "  'back anytim': 0,\n",
              "  'anytim soon': 0,\n",
              "  'food gooodd': 0,\n",
              "  'gooodd far': 0,\n",
              "  'far sushi': 0,\n",
              "  'sushi connoisseur': 0,\n",
              "  'connoisseur definit': 0,\n",
              "  'definit tell': 0,\n",
              "  'tell differ': 0,\n",
              "  'differ good': 0,\n",
              "  'good food': 0,\n",
              "  'food bad': 0,\n",
              "  'bad food': 0,\n",
              "  'food certain': 0,\n",
              "  'certain bad': 0,\n",
              "  'food insult': 0,\n",
              "  'insult last': 0,\n",
              "  'last 3': 0,\n",
              "  '3 time': 0,\n",
              "  'time lunch': 0,\n",
              "  'lunch bad': 0,\n",
              "  'bad chicken': 0,\n",
              "  'chicken wing': 0,\n",
              "  'wing contain': 0,\n",
              "  'contain driest': 0,\n",
              "  'driest chicken': 0,\n",
              "  'chicken meat': 0,\n",
              "  'meat ever': 0,\n",
              "  'ever eaten': 0,\n",
              "  'eaten food': 0,\n",
              "  'food good': 0,\n",
              "  'good enjoy': 0,\n",
              "  'enjoy everi': 0,\n",
              "  'everi mouth': 0,\n",
              "  'mouth enjoy': 0,\n",
              "  'enjoy relax': 0,\n",
              "  'relax venu': 0,\n",
              "  'venu coupl': 0,\n",
              "  'coupl small': 0,\n",
              "  'small famili': 0,\n",
              "  'famili group': 0,\n",
              "  'group etc': 0,\n",
              "  'etc nargil': 0,\n",
              "  'nargil think': 0,\n",
              "  'think great': 0,\n",
              "  'great best': 0,\n",
              "  'best tater': 0,\n",
              "  'tater tot': 0,\n",
              "  'tot southwest': 0,\n",
              "  'southwest love': 0,\n",
              "  'love place': 0,\n",
              "  'place definit': 0,\n",
              "  'definit worth': 0,\n",
              "  'worth 3': 0,\n",
              "  '3 paid': 0,\n",
              "  'paid vanilla': 0,\n",
              "  'vanilla ice': 0,\n",
              "  'ice cream': 0,\n",
              "  'cream creami': 0,\n",
              "  'creami smooth': 0,\n",
              "  'smooth profiterol': 0,\n",
              "  'profiterol choux': 0,\n",
              "  'choux pastri': 0,\n",
              "  'pastri fresh': 0,\n",
              "  'fresh enough': 0,\n",
              "  'enough im': 0,\n",
              "  'im az': 0,\n",
              "  'az time': 0,\n",
              "  'time new': 0,\n",
              "  'new spot': 0,\n",
              "  'spot manag': 0,\n",
              "  'manag worst': 0,\n",
              "  'worst insid': 0,\n",
              "  'insid realli': 0,\n",
              "  'realli quit': 0,\n",
              "  'quit nice': 0,\n",
              "  'nice clean': 0,\n",
              "  'clean food': 0,\n",
              "  'food outstand': 0,\n",
              "  'outstand price': 0,\n",
              "  'price reason': 0,\n",
              "  \"reason n't\": 0,\n",
              "  'll run': 0,\n",
              "  'run back': 0,\n",
              "  'back car': 0,\n",
              "  \"car 's\": 0,\n",
              "  \"'s anytim\": 0,\n",
              "  'food due': 0,\n",
              "  'due fact': 0,\n",
              "  'fact took': 0,\n",
              "  'took 20': 0,\n",
              "  '20 minut': 0,\n",
              "  'minut acknowledg': 0,\n",
              "  'acknowledg anoth': 0,\n",
              "  'anoth 35': 0,\n",
              "  '35 minut': 0,\n",
              "  'minut get': 0,\n",
              "  'get food': 0,\n",
              "  'food ...': 0,\n",
              "  '... kept': 0,\n",
              "  'kept forget': 0,\n",
              "  'forget thing': 0,\n",
              "  'thing love': 0,\n",
              "  'love margarita': 0,\n",
              "  'margarita first': 0,\n",
              "  'buffet disappoint': 0,\n",
              "  'disappoint good': 0,\n",
              "  'good though': 0,\n",
              "  'though one': 0,\n",
              "  'one note': 0,\n",
              "  'note ventil': 0,\n",
              "  'ventil could': 0,\n",
              "  'could use': 0,\n",
              "  'use upgrad': 0,\n",
              "  'upgrad great': 0,\n",
              "  'great pork': 0,\n",
              "  'pork sandwich': 0,\n",
              "  \"sandwich n't\": 0,\n",
              "  \"n't wast\": 0,\n",
              "  'time total': 0,\n",
              "  'total letdown': 0,\n",
              "  'letdown would': 0,\n",
              "  'would much': 0,\n",
              "  'much rather': 0,\n",
              "  'rather go': 0,\n",
              "  'go camelback': 0,\n",
              "  'camelback flower': 0,\n",
              "  'flower shop': 0,\n",
              "  'shop cartel': 0,\n",
              "  'cartel coffe': 0,\n",
              "  'coffe third': 0,\n",
              "  'third chees': 0,\n",
              "  'chees friend': 0,\n",
              "  \"friend 's\": 0,\n",
              "  \"'s burger\": 0,\n",
              "  'burger cold': 0,\n",
              "  'cold enjoy': 0,\n",
              "  'enjoy pizza': 0,\n",
              "  'pizza brunch': 0,\n",
              "  'brunch steak': 0,\n",
              "  'steak well': 0,\n",
              "  'well trim': 0,\n",
              "  'trim also': 0,\n",
              "  'also perfect': 0,\n",
              "  'perfect cook': 0,\n",
              "  'cook group': 0,\n",
              "  'group 70+': 0,\n",
              "  '70+ claim': 0,\n",
              "  'claim would': 0,\n",
              "  'would 40': 0,\n",
              "  '40 handl': 0,\n",
              "  'handl us': 0,\n",
              "  'us beauti': 0,\n",
              "  'beauti love': 0,\n",
              "  'love ask': 0,\n",
              "  'ask bill': 0,\n",
              "  'bill leav': 0,\n",
              "  'leav without': 0,\n",
              "  'without eat': 0,\n",
              "  \"eat n't\": 0,\n",
              "  \"n't bring\": 0,\n",
              "  'bring either': 0,\n",
              "  'either place': 0,\n",
              "  'place jewel': 0,\n",
              "  'jewel las': 0,\n",
              "  'las vega': 0,\n",
              "  'vega exact': 0,\n",
              "  'exact ve': 0,\n",
              "  've hope': 0,\n",
              "  'hope find': 0,\n",
              "  'find near': 0,\n",
              "  'near ten': 0,\n",
              "  'ten year': 0,\n",
              "  'year live': 0,\n",
              "  'live seafood': 0,\n",
              "  'seafood limit': 0,\n",
              "  'limit boil': 0,\n",
              "  'boil shrimp': 0,\n",
              "  'shrimp crab': 0,\n",
              "  'crab leg': 0,\n",
              "  'leg crab': 0,\n",
              "  'leg definit': 0,\n",
              "  'definit tast': 0,\n",
              "  'tast fresh': 0,\n",
              "  'fresh select': 0,\n",
              "  'select food': 0,\n",
              "  'food best': 0,\n",
              "  'best delici': 0,\n",
              "  'delici absolut': 0,\n",
              "  'absolut back': 0,\n",
              "  \"back n't\": 0,\n",
              "  \"n't small\": 0,\n",
              "  'famili restaur': 0,\n",
              "  'restaur fine': 0,\n",
              "  'fine dine': 0,\n",
              "  'dine establish': 0,\n",
              "  'establish toro': 0,\n",
              "  'toro tartar': 0,\n",
              "  'tartar cavier': 0,\n",
              "  'cavier extraordinari': 0,\n",
              "  'extraordinari like': 0,\n",
              "  'like thin': 0,\n",
              "  'thin slice': 0,\n",
              "  'slice wagyu': 0,\n",
              "  'wagyu white': 0,\n",
              "  'white truffl': 0,\n",
              "  'truffl dont': 0,\n",
              "  'dont think': 0,\n",
              "  'think back': 0,\n",
              "  'back long': 0,\n",
              "  'long time': 0,\n",
              "  'time attach': 0,\n",
              "  'attach gas': 0,\n",
              "  'gas station': 0,\n",
              "  'station rare': 0,\n",
              "  'rare good': 0,\n",
              "  'good sign': 0,\n",
              "  'sign awesom': 0,\n",
              "  'awesom back': 0,\n",
              "  'back mani': 0,\n",
              "  'mani time': 0,\n",
              "  'time soon': 0,\n",
              "  'soon menu': 0,\n",
              "  'menu much': 0,\n",
              "  'much good': 0,\n",
              "  'good stuff': 0,\n",
              "  'stuff could': 0,\n",
              "  'could decid': 0,\n",
              "  'decid wors': 0,\n",
              "  'wors humili': 0,\n",
              "  'humili worker': 0,\n",
              "  'worker right': 0,\n",
              "  'right front': 0,\n",
              "  'front ..': 0,\n",
              "  '.. bunch': 0,\n",
              "  'bunch horribl': 0,\n",
              "  'horribl name': 0,\n",
              "  'name call': 0,\n",
              "  'call conclus': 0,\n",
              "  'conclus fill': 0,\n",
              "  'fill meal': 0,\n",
              "  'meal daili': 0,\n",
              "  'daili special': 0,\n",
              "  'special alway': 0,\n",
              "  'hit group': 0,\n",
              "  'group tragedi': 0,\n",
              "  'tragedi struck': 0,\n",
              "  'struck pancak': 0,\n",
              "  'pancak also': 0,\n",
              "  'also realli': 0,\n",
              "  'good pretti': 0,\n",
              "  'pretti larg': 0,\n",
              "  'larg first': 0,\n",
              "  'first crawfish': 0,\n",
              "  'crawfish experi': 0,\n",
              "  'experi delici': 0,\n",
              "  'delici monster': 0,\n",
              "  'monster chicken': 0,\n",
              "  'chicken fri': 0,\n",
              "  'fri steak': 0,\n",
              "  'steak egg': 0,\n",
              "  'egg time': 0,\n",
              "  'time favorit': 0,\n",
              "  'favorit waitress': 0,\n",
              "  'waitress sweet': 0,\n",
              "  'sweet funni': 0,\n",
              "  'funni also': 0,\n",
              "  'also tast': 0,\n",
              "  'tast mom': 0,\n",
              "  \"mom 's\": 0,\n",
              "  \"'s multi-grain\": 0,\n",
              "  'multi-grain pumpkin': 0,\n",
              "  'pumpkin pancak': 0,\n",
              "  'pancak pecan': 0,\n",
              "  'pecan butter': 0,\n",
              "  'butter amaz': 0,\n",
              "  'amaz fluffi': 0,\n",
              "  'fluffi delici': 0,\n",
              "  \"delici 'd\": 0,\n",
              "  \"'d rather\": 0,\n",
              "  'rather eat': 0,\n",
              "  'eat airlin': 0,\n",
              "  'airlin food': 0,\n",
              "  'food serious': 0,\n",
              "  'serious cant': 0,\n",
              "  'cant say': 0,\n",
              "  'say enough': 0,\n",
              "  'enough good': 0,\n",
              "  'good thing': 0,\n",
              "  'thing place': 0,\n",
              "  'place ambianc': 0,\n",
              "  'ambianc incred': 0,\n",
              "  'incred waitress': 0,\n",
              "  'waitress manag': 0,\n",
              "  'manag friend': 0,\n",
              "  'friend would': 0,\n",
              "  'would recommend': 0,\n",
              "  'place overal': 0,\n",
              "  \"overal n't\": 0,\n",
              "  \"n't impress\": 0,\n",
              "  'impress noca': 0,\n",
              "  'noca gyro': 0,\n",
              "  'gyro basic': 0,\n",
              "  'basic lettuc': 0,\n",
              "  'lettuc terribl': 0,\n",
              "  'terribl servic': 0,\n",
              "  'servic thorough': 0,\n",
              "  'thorough disappoint': 0,\n",
              "  \"disappoint n't\": 0,\n",
              "  \"n't much\": 0,\n",
              "  'much pasta': 0,\n",
              "  'pasta love': 0,\n",
              "  'love homemad': 0,\n",
              "  'homemad /hand': 0,\n",
              "  '/hand made': 0,\n",
              "  'made pasta': 0,\n",
              "  'pasta thin': 0,\n",
              "  'thin pizza': 0,\n",
              "  \"pizza n't\": 0,\n",
              "  'know place': 0,\n",
              "  'place manag': 0,\n",
              "  'manag serv': 0,\n",
              "  'serv blandest': 0,\n",
              "  'blandest food': 0,\n",
              "  'food ever': 0,\n",
              "  'eaten prepar': 0,\n",
              "  'prepar indian': 0,\n",
              "  'indian cuisin': 0,\n",
              "  'cuisin worst': 0,\n",
              "  'worst servic': 0,\n",
              "  'servic boot': 0,\n",
              "  'boot least': 0,\n",
              "  'least worri': 0,\n",
              "  'worri servic': 0,\n",
              "  'servic fine': 0,\n",
              "  'fine waitress': 0,\n",
              "  'waitress friend': 0,\n",
              "  'friend guy': 0,\n",
              "  'guy steak': 0,\n",
              "  'steak steak': 0,\n",
              "  'steak love': 0,\n",
              "  'love son': 0,\n",
              "  'son steak': 0,\n",
              "  'steak best': 0,\n",
              "  'best worst': 0,\n",
              "  'worst place': 0,\n",
              "  'place said': 0,\n",
              "  'said best': 0,\n",
              "  'best steak': 0,\n",
              "  \"steak 's\": 0,\n",
              "  \"'s ever\": 0,\n",
              "  'eaten thought': 0,\n",
              "  \"thought 'd\": 0,\n",
              "  \"'d ventur\": 0,\n",
              "  'ventur away': 0,\n",
              "  'away get': 0,\n",
              "  'get good': 0,\n",
              "  'good sushi': 0,\n",
              "  'sushi place': 0,\n",
              "  'place realli': 0,\n",
              "  'realli hit': 0,\n",
              "  'hit spot': 0,\n",
              "  'spot night': 0,\n",
              "  'night host': 0,\n",
              "  'host staff': 0,\n",
              "  'staff lack': 0,\n",
              "  'lack better': 0,\n",
              "  'better word': 0,\n",
              "  'word bitch': 0,\n",
              "  'bitch bland': 0,\n",
              "  'bland ...': 0,\n",
              "  '... like': 0,\n",
              "  'place number': 0,\n",
              "  'number reason': 0,\n",
              "  \"n't want\": 0,\n",
              "  'want wast': 0,\n",
              "  'time bad': 0,\n",
              "  'bad review': 0,\n",
              "  'review ..': 0,\n",
              "  '.. ll': 0,\n",
              "  'll leav': 0,\n",
              "  'leav ...': 0,\n",
              "  '... phenomen': 0,\n",
              "  'phenomen food': 0,\n",
              "  'food servic': 0,\n",
              "  'servic ambianc': 0,\n",
              "  'ambianc would': 0,\n",
              "  \"would n't\": 0,\n",
              "  \"n't return\": 0,\n",
              "  'return definit': 0,\n",
              "  'worth ventur': 0,\n",
              "  'ventur strip': 0,\n",
              "  'strip pork': 0,\n",
              "  'pork belli': 0,\n",
              "  'belli return': 0,\n",
              "  'return next': 0,\n",
              "  \"time 'm\": 0,\n",
              "  \"'m vega\": 0,\n",
              "  'vega place': 0,\n",
              "  'way overpr': 0,\n",
              "  'overpr mediocr': 0,\n",
              "  'mediocr food': 0,\n",
              "  'food penn': 0,\n",
              "  'penn vodka': 0,\n",
              "  'vodka excel': 0,\n",
              "  'excel good': 0,\n",
              "  'good select': 0,\n",
              "  'food includ': 0,\n",
              "  'includ massiv': 0,\n",
              "  'massiv meatloaf': 0,\n",
              "  'meatloaf sandwich': 0,\n",
              "  'sandwich crispi': 0,\n",
              "  'crispi chicken': 0,\n",
              "  'chicken wrap': 0,\n",
              "  'wrap delish': 0,\n",
              "  'delish tuna': 0,\n",
              "  'tuna melt': 0,\n",
              "  'melt tasti': 0,\n",
              "  'tasti burger': 0,\n",
              "  'burger manag': 0,\n",
              "  'manag rude': 0,\n",
              "  'rude delici': 0,\n",
              "  'delici nyc': 0,\n",
              "  'nyc bagel': 0,\n",
              "  'bagel good': 0,\n",
              "  'select cream': 0,\n",
              "  ...},\n",
              " '0')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me2He0cOOzEM",
        "outputId": "21f91ad9-fee1-4f8a-e229-26377d0884d8"
      },
      "source": [
        "classifier = NaiveBayesClassifier.train(train_set)\n",
        "accuracy = classify.accuracy(classifier, test_set)\n",
        "print(\"Accuracy: \", accuracy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY4EyeA_Mxc4"
      },
      "source": [
        "The accuracy is not good. Why?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tagF7hqP9L3",
        "outputId": "9eb0eea6-ecd1-4766-9de5-11c5c286b5d4"
      },
      "source": [
        "print(f\"Original: {X_train_tokens[0]}\")\n",
        "print(f\"Processed: {X_train_tokens_processed[0]}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: (['so', 'there', 'is', 'no', 'way', 'for', 'me', 'to', 'plug', 'it', 'in', 'here', 'in', 'the', 'us', 'unless', 'i', 'go', 'by', 'a', 'converter', '.'], '0')\n",
            "Processed: (['way', 'plug', 'us', 'unless', 'go', 'convert'], '0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StxTEZhSSSdX",
        "outputId": "f8b190be-f34b-4b63-af41-0b4fbfd546ae"
      },
      "source": [
        "from nltk import ngrams\n",
        "\n",
        "def get_bigrams(word_tokens, n=2):\n",
        "  n_grams = ngrams(word_tokens, n)\n",
        "  return [ ' '.join(grams) for grams in n_grams]\n",
        "\n",
        "vocab_bigram = get_bigrams(all_word_list)\n",
        "X_train_bigram = [(get_bigrams(x[0]),x[1]) for x in X_train_tokens]\n",
        "X_test_bigram = [(get_bigrams(x[0]),x[1]) for x in X_test_tokens]\n",
        "\n",
        "train_set = generate_vectors(X_train_bigram, vocab = vocab_bigram)\n",
        "test_set = generate_vectors(X_test_bigram, vocab = vocab_bigram)\n",
        "\n",
        "classifier = NaiveBayesClassifier.train(train_set)\n",
        "accuracy = classify.accuracy(classifier, test_set)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKDSvcEbP5sn"
      },
      "source": [
        "## Combining Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x956QegEQy9q",
        "outputId": "f62a3787-43ba-4485-e597-7b27c3e4809b"
      },
      "source": [
        "def combine_tokens(data1, data2):\n",
        "    final_list = []\n",
        "    for x,y in zip(data1, data2):\n",
        "        a = []\n",
        "        for tokens_x, tokens_y in zip(x[0],y[0]):\n",
        "            a.append(tokens_x)\n",
        "            a.append(tokens_y)\n",
        "        final_list.append((a, x[1]))\n",
        "    return final_list\n",
        "\n",
        "X_train_combined = combine_tokens(X_train_tokens_processed, X_train_bigram)\n",
        "X_test_combined = combine_tokens(X_test_tokens_processed, X_test_bigram)\n",
        "X_train_combined[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['way',\n",
              "  'so there',\n",
              "  'plug',\n",
              "  'there is',\n",
              "  'us',\n",
              "  'is no',\n",
              "  'unless',\n",
              "  'no way',\n",
              "  'go',\n",
              "  'way for',\n",
              "  'convert',\n",
              "  'for me'],\n",
              " '0')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQHfbYmbSwTi",
        "outputId": "b23582f2-8ba3-4e39-b1fb-6c86e7e15d78"
      },
      "source": [
        "fdist = FreqDist(stemmed_filtered_word_list+vocab_bigram)\n",
        "combined_vocab_most_common = [x[0] for x in fdist.most_common(2000)]\n",
        "train_set = generate_vectors(X_train_combined, vocab = combined_vocab_most_common)\n",
        "test_set = generate_vectors(X_test_combined, vocab = combined_vocab_most_common)\n",
        "\n",
        "vocab_length = len(train_set[0][0].items())\n",
        "vocab_length\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11Zn1NQDS1Fe",
        "outputId": "c49321e8-f214-4c4a-8cfb-f9c75dc25dcc"
      },
      "source": [
        "classifier = NaiveBayesClassifier.train(train_set)\n",
        "accuracy = classify.accuracy(classifier, test_set)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeDQ481NS1sI"
      },
      "source": [
        "It depends a lot on the quality of the vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q13jf2DKT_Qr"
      },
      "source": [
        "## Important Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAukmt1ZT-c1",
        "outputId": "f02268d4-b305-47b5-d03f-954d282b35fe"
      },
      "source": [
        "classifier.show_most_informative_features(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "                   excel = 1                   1 : 0      =     34.3 : 1.0\n",
            "                     bad = 1                   0 : 1      =     21.4 : 1.0\n",
            "                 terribl = 1                   0 : 1      =     21.3 : 1.0\n",
            "                   worst = 1                   0 : 1      =     20.6 : 1.0\n",
            "                 perfect = 1                   1 : 0      =     19.4 : 1.0\n",
            "                   great = 1                   1 : 0      =     18.6 : 1.0\n",
            "                   money = 1                   0 : 1      =     17.3 : 1.0\n",
            "                   happi = 1                   1 : 0      =     16.0 : 1.0\n",
            "                    love = 1                   1 : 0      =     16.0 : 1.0\n",
            "                      aw = 1                   0 : 1      =     13.4 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCsKKv3BAN9g"
      },
      "source": [
        "# Word2Vec Tutorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPuuleOCAN9l"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import Phrases\n",
        "from gensim.models.phrases import Phraser\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8Xw9_HmAN9v"
      },
      "source": [
        "## Exploring the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_P7-GD3-yvR",
        "outputId": "a067715c-2389-4668-dd2d-f6d9fc1967cd"
      },
      "source": [
        "!wget -O \"hotel-reviews.csv\" \"https://easyupload.io/4rtsel\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-19 21:01:23--  https://easyupload.io/4rtsel\n",
            "Resolving easyupload.io (easyupload.io)... 104.26.3.69, 104.26.2.69, 172.67.71.25, ...\n",
            "Connecting to easyupload.io (easyupload.io)|104.26.3.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘hotel-reviews.csv’\n",
            "\n",
            "hotel-reviews.csv       [ <=>                ]  19.93K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-07-19 21:01:23 (132 MB/s) - ‘hotel-reviews.csv’ saved [20412]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc9xhBZdAN9v"
      },
      "source": [
        "data = pd.read_csv('hotel-reviews.csv',sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Erfyv0O5AN91",
        "outputId": "879a8403-e0cf-44a2-a3e8-157d74b29640"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     <!DOCTYPE html>\n",
              "0                                   <html lang=\"en\">\n",
              "1                                             <head>\n",
              "2  <script async src=\"https://www.googletagmanage...\n",
              "3  <script type=\"7af194871226a88f2db250f9-text/ja...\n",
              "4         window.dataLayer = window.dataLayer || [];"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-c53e37ae-d5ac-499e-b0ae-b9151bf153c1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>&lt;!DOCTYPE html&gt;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;html lang=\"en\"&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;head&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;script async src=\"https://www.googletagmanage...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;script type=\"7af194871226a88f2db250f9-text/ja...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>window.dataLayer = window.dataLayer || [];</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c53e37ae-d5ac-499e-b0ae-b9151bf153c1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-249138c0-6d70-499a-909a-e71d34e34e82\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-249138c0-6d70-499a-909a-e71d34e34e82')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-249138c0-6d70-499a-909a-e71d34e34e82 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c53e37ae-d5ac-499e-b0ae-b9151bf153c1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c53e37ae-d5ac-499e-b0ae-b9151bf153c1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBN6WHiCAN-C",
        "outputId": "ef4d35b5-09f5-490f-f387-9bdf2efad89d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       <!DOCTYPE html>\n",
              "count              399\n",
              "unique             233\n",
              "top             </div>\n",
              "freq                36"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-1b5d435c-8a73-441c-96f1-931c6e886703\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>&lt;!DOCTYPE html&gt;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>&lt;/div&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b5d435c-8a73-441c-96f1-931c6e886703')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-a4bcc1ba-2076-4d38-aced-1e32a10dff36\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a4bcc1ba-2076-4d38-aced-1e32a10dff36')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-a4bcc1ba-2076-4d38-aced-1e32a10dff36 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b5d435c-8a73-441c-96f1-931c6e886703 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b5d435c-8a73-441c-96f1-931c6e886703');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VYgNiTBAN-J",
        "outputId": "617fdda2-2725-4b6a-e9b8-0d2de42ae123"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 399 entries, 0 to 398\n",
            "Data columns (total 1 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   <!DOCTYPE html>  399 non-null    object\n",
            "dtypes: object(1)\n",
            "memory usage: 3.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH60BVsPAN-M"
      },
      "source": [
        "We are interested in Description column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2z2prauAN_L",
        "outputId": "06dc3ce5-253c-4d14-f526-8a65451aa16e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# get stop words from nltk\n",
        "stopWords = stopwords.words('english')\n",
        "\n",
        "# pre processing data\n",
        "def cleanData(sentence):\n",
        "    processedList = \"\"\n",
        "\n",
        "    # convert to lowercase, ignore all special characters - keep only alpha-numericals and spaces (not removing full-stop here)\n",
        "    sentence = re.sub(r'[^A-Za-z0-9\\s.]',r'',str(sentence).lower())\n",
        "    sentence = re.sub(r'\\n',r' ',sentence)\n",
        "\n",
        "    # remove stop words\n",
        "    sentence = \" \".join([word for word in sentence.split() if word not in stopWords])\n",
        "\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1gPSerRAOAJ"
      },
      "source": [
        "Sample processed review:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "0npm-v29AOAS",
        "outputId": "7b08b04d-c2b2-47a9-b554-923eefb23796"
      },
      "source": [
        "cleanData(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'doctype html 0 html langen 1 head 2 script async srchttpswww.googletagmanage... 3 script type7af194871226a88f2db250f9textja... 4 window.datalayer window.datalayer .. ... 394 395 script 396 script srccdncgiscripts7d0fa10acloudfl... 397 body 398 html 399 rows x 1 columns'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfy74mARAOAY"
      },
      "source": [
        "Process the whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o4e4bqeAOAZ",
        "outputId": "7fb3cdc5-5dfb-4cf7-e77e-a35f5ea270be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        }
      },
      "source": [
        "# clean data\n",
        "data['Description'] = data['Description'].map(lambda x: cleanData(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Description'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-22f365b92f42>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# clean data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Description'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcleanData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Description'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SxM4CninAOAe",
        "outputId": "c4464fa5-0230-4349-cc09-ff83c763c698"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     <!DOCTYPE html>\n",
              "0                                   <html lang=\"en\">\n",
              "1                                             <head>\n",
              "2  <script async src=\"https://www.googletagmanage...\n",
              "3  <script type=\"7af194871226a88f2db250f9-text/ja...\n",
              "4         window.dataLayer = window.dataLayer || [];"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-3180a7f5-0168-4b82-be46-296310b5d56a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>&lt;!DOCTYPE html&gt;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;html lang=\"en\"&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;head&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;script async src=\"https://www.googletagmanage...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;script type=\"7af194871226a88f2db250f9-text/ja...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>window.dataLayer = window.dataLayer || [];</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3180a7f5-0168-4b82-be46-296310b5d56a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-1ed38885-79f5-4046-9d04-beff105a49b5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1ed38885-79f5-4046-9d04-beff105a49b5')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-1ed38885-79f5-4046-9d04-beff105a49b5 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3180a7f5-0168-4b82-be46-296310b5d56a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3180a7f5-0168-4b82-be46-296310b5d56a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0RMoeEuAOAm"
      },
      "source": [
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wITiDPwFAOAm"
      },
      "source": [
        "Going to use [gensim](https://radimrehurek.com/gensim/models/word2vec.html) library to train word2vec model. Gensim accepts input in form of list of lists, where each internal list consists of review sentence.  \n",
        "  \n",
        "Each review in our data may have more than one sentence. We'll split each sentence and create a list of sentences to pass it to gensim."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVs8td38AOAn",
        "outputId": "71a6c67c-e497-4f08-f3f1-b17c02ea0893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        }
      },
      "source": [
        "tmp_corpus = data['Description'].map(lambda x: x.split('.'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Description'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-7373dcdb7d95>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Description'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "uyej7dUEAOAr",
        "outputId": "8044fcf6-16f9-45c8-ba17-3fcc59c9ba01"
      },
      "source": [
        "# corpus [[w1,w2,w3..],[..]]\n",
        "corpus = []\n",
        "for i in tqdm(range(len(tmp_corpus))):\n",
        "    for line in tmp_corpus[i]:\n",
        "        words = [x for x in line.split()]\n",
        "        corpus.append(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-a64f828917b6>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# corpus [[w1,w2,w3..],[..]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp_corpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tmp_corpus' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRdedLAWAOAv"
      },
      "source": [
        "Our data contains **444k** sentences and **3111k** words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxEC_kAKAOAw",
        "outputId": "2f75f225-3ccd-410a-e67c-6f26ead75c5c"
      },
      "source": [
        "num_of_sentences = len(corpus)\n",
        "num_of_words = 0\n",
        "for line in corpus:\n",
        "    num_of_words += len(line)\n",
        "\n",
        "print('Num of sentences - %s'%(num_of_sentences))\n",
        "print('Num of words - %s'%(num_of_words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of sentences - 0\n",
            "Num of words - 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKSjRkXdAOA8"
      },
      "source": [
        "**We'll do a little more preprocessing here by extracting phrases from the corpus. For example, new york -> new_york, etc. We'll limit to only bigrams.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bySXXRTqAOA8",
        "scrolled": true
      },
      "source": [
        "phrases = Phrases(sentences=corpus,min_count=25,threshold=50)\n",
        "bigram = Phraser(phrases)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUGhzQeYAOBD"
      },
      "source": [
        "for index, sentence in enumerate(corpus):\n",
        "    corpus[index] = bigram[sentence]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDR9KPrRAOBG"
      },
      "source": [
        "import random\n",
        "# shuffle corpus\n",
        "def shuffle_corpus(sentences):\n",
        "    shuffled = list(sentences)\n",
        "    random.shuffle(shuffled)\n",
        "    return shuffled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "SvR9EsdsAOBI",
        "scrolled": true,
        "outputId": "309cc519-885a-4e3d-9bd8-4053d1214bb7"
      },
      "source": [
        "# sg - skip gram |  window = size of the window | size = vector dimension\n",
        "size = 100\n",
        "window_size = 2 # sentences weren't too long, so\n",
        "epochs = 5\n",
        "min_count = 2\n",
        "workers = 4\n",
        "\n",
        "# train word2vec model using gensim\n",
        "model = Word2Vec(corpus, sg=1,window=window_size,size=size,\n",
        "                 min_count=min_count, workers=workers, iter=epochs, sample=0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-8b3541c26aa3>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# train word2vec model using gensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m model = Word2Vec(corpus, sg=1,window=window_size,size=size,\n\u001b[0m\u001b[1;32m     10\u001b[0m                  min_count=min_count, workers=workers, iter=epochs, sample=0.01)\n",
            "\u001b[0;31mTypeError\u001b[0m: Word2Vec.__init__() got an unexpected keyword argument 'size'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K81xj4DuAOBM"
      },
      "source": [
        "If you want to extend training - also called online word2vec training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "collapsed": true,
        "id": "LtklUdEpAOBP",
        "scrolled": true,
        "outputId": "04dda934-5672-4b9c-f9de-87b32f7d348f"
      },
      "source": [
        "model.build_vocab(sentences=shuffle_corpus(corpus),update=True)\n",
        "\n",
        "model.train(sentences=shuffle_corpus(corpus),epochs=2,total_examples=model.corpus_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-fcae7b049b05>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD2yLvp9AOBV"
      },
      "source": [
        "Save word2vec model to load and use later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "rtvjecacAOB6",
        "outputId": "36f47ff2-d27c-41ab-eb81-d131ee86f278"
      },
      "source": [
        "# save model\n",
        "model.save('w2v_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-4abf5e26ae83>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'w2v_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3wFjmfZAOB-"
      },
      "source": [
        "Or load already saved word2vec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "i69Jv53DAOB-",
        "outputId": "174efb9d-26be-4689-f6e1-a7529e609b33"
      },
      "source": [
        "# load word2vec model\n",
        "model = Word2Vec.load('w2v_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-baeb90923d9f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load word2vec model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'w2v_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, rethrow, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1951\u001b[0m         \"\"\"\n\u001b[1;32m   1952\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1953\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1954\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1955\u001b[0m                 \u001b[0mrethrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_lifecycle_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \"\"\"\n\u001b[0;32m-> 1460\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1461\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# needed because loading from S3 doesn't support readline()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mtransport_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     fobj = _shortcut_open(\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'errors'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'w2v_model'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz_kX6PVAOCM"
      },
      "source": [
        "## Using the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnyH8kFrAOCN"
      },
      "source": [
        "Word2vec training is an unsupervised task, there’s no good way to objectively evaluate the result. Evaluation depends on your end application."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "vB9DVL_5AOCN",
        "outputId": "bda44433-4820-40cf-b778-95bd1ab6d633"
      },
      "source": [
        "model.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-e135a8181f96>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'woman'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'king'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'man'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "md9VPcpkAOCQ",
        "outputId": "169a0cc8-1a71-4fe6-a547-9597270005b9"
      },
      "source": [
        "model.wv.most_similar(positive=['hotel', 'room'], negative=['cafe'], topn=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-37467bb847a6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hotel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'room'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cafe'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAuCp2UrAOCX",
        "outputId": "34bee89f-b826-42a1-a69c-2d505b6f8782"
      },
      "source": [
        "model.most_similar(positive=['happy', 'sad'], negative=['annoy'], topn=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('pleased', 0.5729702711105347),\n",
              " ('delighted', 0.5307438969612122),\n",
              " ('impressed', 0.5188437700271606),\n",
              " ('disappointed', 0.5059719681739807),\n",
              " ('glad', 0.5015227198600769),\n",
              " ('excited', 0.49853354692459106),\n",
              " ('thrilled', 0.49636369943618774),\n",
              " ('satisfied', 0.4903351366519928),\n",
              " ('pleasantly_surprised', 0.4680972397327423),\n",
              " ('suprised', 0.46571704745292664)]"
            ]
          },
          "execution_count": 32,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_cSiDDTAOCd"
      },
      "source": [
        "### The results look promising. Word2vec is pretty good in understanding the semantics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "FQduWWRJAOCd",
        "outputId": "d1e8bea9-beae-4c40-e27f-ed569f85366b"
      },
      "source": [
        "model.wv.doesnt_match('hotel nice clean holiday'.split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'holiday'"
            ]
          },
          "execution_count": 33,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "ki7FWblLAOCi",
        "outputId": "eb4628e4-e6f7-470d-df51-7b4b28875c66"
      },
      "source": [
        "model.wv.doesnt_match('breakfast dinner continental lunch'.split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'continental'"
            ]
          },
          "execution_count": 34,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wySIfsqbAOCk",
        "outputId": "82d08814-4725-4f18-b974-b5e3ffecc08f"
      },
      "source": [
        "model.wv.similarity('dinner','lunch')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.79660386"
            ]
          },
          "execution_count": 35,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkoFvcztAOCo",
        "outputId": "986a203d-8d79-4031-9e3f-6c9c3be87873"
      },
      "source": [
        "model.wv.similarity('trump','orange')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.17030844"
            ]
          },
          "execution_count": 36,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuR2eQ1oAOCt",
        "outputId": "3d18567f-39a2-4f0a-b2b0-398e32fac818"
      },
      "source": [
        "model.wv.most_similar('great')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('fantastic', 0.8839520215988159),\n",
              " ('excellent', 0.8770525455474854),\n",
              " ('terrific', 0.872854471206665),\n",
              " ('awesome', 0.8426216840744019),\n",
              " ('fab', 0.8374155163764954),\n",
              " ('wonderful', 0.8373751044273376),\n",
              " ('fabulous', 0.832792341709137),\n",
              " ('amazing', 0.8165019750595093),\n",
              " ('brilliant', 0.8028467893600464),\n",
              " ('sensational', 0.8012031316757202)]"
            ]
          },
          "execution_count": 37,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbTImQWGAOCx",
        "outputId": "39c7d3ac-ebcd-43e1-a755-1e24f7145b52"
      },
      "source": [
        "model.wv.most_similar('comfortable')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('comfy', 0.872967004776001),\n",
              " ('comfotable', 0.7963284254074097),\n",
              " ('confortable', 0.7941827774047852),\n",
              " ('nicely_furnished', 0.7758354544639587),\n",
              " ('comforatable', 0.7724374532699585),\n",
              " ('cosy', 0.7478086948394775),\n",
              " ('comforable', 0.7471197843551636),\n",
              " ('welldesigned', 0.739068865776062),\n",
              " ('well_appointed', 0.7379303574562073),\n",
              " ('nicely_appointed', 0.7328687906265259)]"
            ]
          },
          "execution_count": 38,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-CnXS5IAODB",
        "outputId": "71e0ad31-23b5-49a1-ff81-53faa5af3cba"
      },
      "source": [
        "model.wv.most_similar('recommend')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('recomend', 0.8663480877876282),\n",
              " ('reccommend', 0.8577518463134766),\n",
              " ('highly_recommend', 0.8566358089447021),\n",
              " ('reccomend', 0.8566051125526428),\n",
              " ('recommed', 0.8093087673187256),\n",
              " ('suggest', 0.7764472365379333),\n",
              " ('strongly_recommend', 0.7740464210510254),\n",
              " ('recomment', 0.7602987289428711),\n",
              " ('recommand', 0.7385482788085938),\n",
              " ('recommened', 0.728691577911377)]"
            ]
          },
          "execution_count": 39,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ltFXyz-AODE",
        "outputId": "c13a9112-4563-4c32-ccc6-2b34cf89bb0b"
      },
      "source": [
        "model.wv.most_similar('boston')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('chicago', 0.867302417755127),\n",
              " ('seattle', 0.8585428595542908),\n",
              " ('san_francisco', 0.8462274074554443),\n",
              " ('dc', 0.829149067401886),\n",
              " ('san_fran', 0.8142703175544739),\n",
              " ('san_antonio', 0.8081560134887695),\n",
              " ('sf', 0.808082640171051),\n",
              " ('san_diego', 0.8080612421035767),\n",
              " ('austin', 0.8053025603294373),\n",
              " ('sd', 0.7997270822525024)]"
            ]
          },
          "execution_count": 40,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbkqLTsZAOEZ",
        "scrolled": true,
        "outputId": "d5930974-df06-4d5e-ddc4-e2409d4611fe"
      },
      "source": [
        "model.wv['hotel'] # d-dimension vector"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.11967003, -0.26200476, -0.07242464, -0.0221924 , -0.69130605,\n",
              "        0.01092981, -0.14786133, -0.06060146,  0.01936279,  0.05829052,\n",
              "        0.6324063 ,  0.03178343,  0.38170835, -0.12574847,  0.1225446 ,\n",
              "       -0.24900924, -0.3259418 , -0.12208169, -0.2092189 , -0.7135073 ,\n",
              "       -0.4306573 , -0.15086758, -0.36022285,  0.23711286, -0.30095556,\n",
              "       -0.06402199, -0.08092712, -0.10469051,  0.15704407, -0.30169517,\n",
              "        0.09509814, -0.15459746,  0.4668732 , -0.43557364, -0.20660453,\n",
              "        0.05819632,  0.19726731, -0.11724408, -0.5689755 , -0.14679305,\n",
              "       -0.03234003, -0.20351206,  0.5422662 , -0.05723775, -0.11397955,\n",
              "       -0.2598363 , -0.28728083,  0.22430855,  0.41474628,  0.07220713,\n",
              "        0.5558087 , -0.07409149, -0.3327796 ,  0.266911  , -0.6240864 ,\n",
              "        0.21333385,  0.25587645,  0.2698985 ,  0.30298597, -0.11262956,\n",
              "        0.4143406 , -0.08314233,  0.28369722,  0.5080995 ,  0.09111518,\n",
              "       -0.1144664 , -0.39422366, -0.03235864,  0.3767159 , -0.42418796,\n",
              "       -0.06107952, -0.40712735, -0.10292973, -0.01154223,  0.16499636,\n",
              "       -0.38615292,  0.3777089 , -0.2743428 , -0.02456807, -0.38630405,\n",
              "       -0.25105894,  0.05096208,  0.47882476,  0.27028546,  0.0418848 ,\n",
              "        0.56214327,  0.14909032, -0.05640813, -0.05145195,  0.14513563,\n",
              "        0.3397255 , -0.07868467,  0.28701675,  0.39292192, -0.29049736,\n",
              "        0.12039238,  0.06740264,  0.16564462,  0.5542157 , -0.40327623],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 41,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKQD77NhEaub"
      },
      "source": [
        "# References\n",
        "\n",
        "\n",
        "*   https://www.nltk.org/book/\n",
        "*   https://github.com/hb20007/hands-on-nltk-tutorial\n",
        "*   https://colab.research.google.com/github/DerwenAI/spaCy_tuTorial/blob/master/spaCy_tuTorial.ipynb\n",
        "*  http://jalammar.github.io/illustrated-word2vec/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8UKqmaSEcYo"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "**SVD, Word2Vec, TSNE**\n",
        "\n",
        "1.   Generate a co-occurance matrix with window size = 2. Represent each review with a dense vector extracted from SVD where dimension = 300. Re-train the model on the IMDB dataset and report the accuracy on the test-set.\n",
        "2.   Train word2vec model on the IMDB dataset using gensim library and save the word embeddings.\n",
        "3.  Use the saved representations above with an algorithm of your choice from Sklearn and compare the results with our results [above](https://colab.research.google.com/drive/1DcQE2q4ioHVXA-zQvoGMzxpFKtaDRglG#scrollTo=11Zn1NQDS1Fe&line=1&uniqifier=1)\n",
        "4. Visualize the word2vec embeddings learned above using [t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)  \n",
        "\n"
      ]
    }
  ]
}