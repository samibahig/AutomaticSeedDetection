{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeedForward.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samibahig/AutomaticSeedDetection/blob/main/FeedForward.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESHPiDyG1P77"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option(\"max_columns\", None)\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# Acquisition des données et Affichage\n",
        "df = pd.read_csv(\"diabetes_012_health_indicators_BRFSS2015.csv\")\n",
        "print('VOICI LE CONTENU DU DATAFRAME df')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df['Diabetes_012'] == 2, 'Diabetes_012'] -= 1"
      ],
      "metadata": {
        "id": "C-Jez6N_1_EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.drop(columns = ['CholCheck', 'Income', 'Stroke','HighChol','Education', 'DiffWalk', 'NoDocbcCost', 'AnyHealthcare'], axis=1)"
      ],
      "metadata": {
        "id": "2CMl8OCg2B0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "id": "2fMiOXd52KF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "id": "wTyqwGr72PNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr=df2.corr()\n",
        "corr=corr.round(2)\n",
        "f,ax = plt.subplots(figsize=(10,8))\n",
        "sns.heatmap(corr)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DtIShv5v-o5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Puisque nous avons des outliers, nous allons utilisé un Robust Scaler pour la standardisation"
      ],
      "metadata": {
        "id": "VTncxBbt_Bj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "sc =  RobustScaler()\n",
        "df_std = sc.fit_transform(df2)\n",
        "df_std = pd.DataFrame(df_std)\n",
        "df_std.head()"
      ],
      "metadata": {
        "id": "VU5AJuelILi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_std"
      ],
      "metadata": {
        "id": "y2b0XO4uITQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_std.fillna(df_std.mean(), inplace=True)"
      ],
      "metadata": {
        "id": "R9uyuq57IZYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_std"
      ],
      "metadata": {
        "id": "o_ERHXMZIjYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df2['Diabetes_012']\n",
        "X = df2.drop('Diabetes_012', axis = 1)"
      ],
      "metadata": {
        "id": "sYOrZwMSMwld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 44)"
      ],
      "metadata": {
        "id": "UzPF2872MyJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = x_train, y_train"
      ],
      "metadata": {
        "id": "vOv5MZR3LOK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = x_test, y_test"
      ],
      "metadata": {
        "id": "GKK0JaZvM8zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "n_iters = 90000\n",
        "#num_epochs = n_iters / (len(x_train) / batch_size)\n",
        "#num_epochs = int(num_epochs)"
      ],
      "metadata": {
        "id": "lO8g0j1KOZfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x_train)"
      ],
      "metadata": {
        "id": "Av1wm476ptMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs"
      ],
      "metadata": {
        "id": "1tRs4hqIi6-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "doU4UB04hLSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "buRR4AR_iBkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "RZpzBRya03Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedforwardNeuralNetModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FeedforwardNeuralNetModel, self).__init__()\n",
        "        # Linear function\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
        "        # Non-linearity\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        # Linear function (readout)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)  \n",
        "\n",
        "    def forward(self, x):\n",
        "        # Linear function  # LINEAR\n",
        "        out = self.fc1(x)\n",
        "        # Non-linearity  # NON-LINEAR\n",
        "        out = self.sigmoid(out)\n",
        "        # Linear function (readout)  # LINEAR\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "6xnJSp-0I7to"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 13\n",
        "hidden_dim = 100\n",
        "output_dim = 1\n",
        "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)"
      ],
      "metadata": {
        "id": "gezM6tybJT95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "9VOhMOIYTwm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.075\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) "
      ],
      "metadata": {
        "id": "laeHnTtHT0E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.parameters())\n",
        "print(len(list(model.parameters())))\n",
        "# FC 1 Parameters \n",
        "print(list(model.parameters())[0].size())\n",
        "# FC 1 Bias Parameters\n",
        "print(list(model.parameters())[1].size())\n",
        "# FC 2 Parameters\n",
        "print(list(model.parameters())[2].size())\n",
        "# FC 2 Bias Parameters\n",
        "print(list(model.parameters())[3].size())"
      ],
      "metadata": {
        "id": "2ZnCeGBvT5uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Pandas to numpy, and\n",
        "x_train_numpy = x_train.to_numpy()\n",
        "x_train_tensor = torch.from_numpy(x_train_numpy)\n",
        "y_train_numpy = y_train.to_numpy()\n",
        "y_train_tensor = torch.from_numpy(y_train_numpy)\n",
        "print(x_train_tensor, y_train_tensor)"
      ],
      "metadata": {
        "id": "R3qM_uVVsi-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Pandas to numpy, and\n",
        "x_test_numpy = x_test.to_numpy()\n",
        "x_test_tensor = torch.from_numpy(x_test_numpy)\n",
        "y_test_numpy = y_test.to_numpy()\n",
        "y_test_tensor = torch.from_numpy(y_test_numpy)\n",
        "print(x_test_tensor, y_test_tensor)"
      ],
      "metadata": {
        "id": "yYzsEnkDt8Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_tensor = y_train_tensor.unsqueeze(1)\n",
        "y_test_tensor = y_test_tensor.unsqueeze(1)"
      ],
      "metadata": {
        "id": "mha6we-luq8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_tensor"
      ],
      "metadata": {
        "id": "hShdJi--vCQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_tensor"
      ],
      "metadata": {
        "id": "C3vOHOgwvHc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)"
      ],
      "metadata": {
        "id": "YIusM_Mvv-WV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = torch.utils.data.TensorDataset(x_test_tensor, y_test_tensor)"
      ],
      "metadata": {
        "id": "ZU98XhkjwEEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset[0]"
      ],
      "metadata": {
        "id": "oBnFZhANwhSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "HdJcf-_XV6wD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x_test, y_test in validation_loader:\n",
        "    # Forward pass only to get logits/output\n",
        "    outputs = model(x_test.float())\n",
        "    #print(outputs)\n",
        "    #print(y_test[0])"
      ],
      "metadata": {
        "id": "U9Frc3DrKdv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display image and label.\n",
        "#x_test, y_test = validation_loader\n",
        "##print(f\"Feature batch shape: {x_test_features.size()}\")\n",
        "#print(f\"Labels batch shape: {y_test_labels.size()}\")\n",
        "##img = x_test[0].squeeze()\n",
        "##label = y_test[0]\n",
        "##plt.imshow(img, cmap=\"gray\")\n",
        "##plt.show()\n",
        "##print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "Hoh5XSJ5N6b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test\n",
        "#y_test\n",
        "#x_test"
      ],
      "metadata": {
        "id": "LEVzw2o8f5fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' STEP 7: TRAIN THE MODEL '''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for x_train, y_train in training_loader:\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(x_train.float())   \n",
        "        #outputs = model(x_test[0].float())\n",
        "    #print(outputs)\n",
        "        #(outputs)     \n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, y_train.float())\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "        # Updating parameters\n",
        "        optimizer.step()        \n",
        "        iter += 1\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            #example =  x_test\n",
        "            for x_test, y_test in validation_loader:\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(x_test.float())\n",
        "                m = nn.Sigmoid()\n",
        "                #input = torch.randn(2)\n",
        "                Normalized_output = m(outputs)\n",
        "                #print( Normalized_output)\n",
        "                predictions = Normalized_output > 0.5\n",
        "                predictions_integer = predictions.long()\n",
        "                #print(predictions)\n",
        "                #print(outputs)\n",
        "                # Get predictions from the maximum value\n",
        "                #_, predicted = torch.max(outputs.data, 1)\n",
        "                #print(outputs.data, 1)\n",
        "                # Total number of labels\n",
        "                total += y_test.size(0)  \n",
        "                #print(total)              \n",
        "                # Total correct predictions\n",
        "                correct += (predictions_integer == y_test).sum()\n",
        "                #print(correct)\n",
        "            accuracy = 100 * correct / total\n",
        "            #print(total)\n",
        "            #print(correct)\n",
        "            #print(accuracy)\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "metadata": {
        "id": "oR3l4KsShNBI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}